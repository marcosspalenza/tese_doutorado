% ==============================================================================
% TCC - Nome do Aluno
% Capítulo 1 - Introdução
% ==============================================================================
\chapter{Introdução}
\label{cap1-intro}

A Classificação de Documentos é uma abrangente área de estudo que têm característica multidisciplinar. Dentre larga escala de documentos, esta é parte fundamental para redução de esforço de avaliação e aumento exponencial da capacidade analítica humana. Por meio destes métodos, são adicionados rótulos aos documentos que caracterizam seu conteúdo segundo temas objetivos ou subjetivos. A subjetividade da classificação é algo que torna ainda mais complexa a análise pois documentos individualmente podem não representar o contexto geral ou ter a semântica dos termos empregados. Por isso, a categorização pode passar por processos mais complexos do que a identificação direta de termos que estão associados à classe.

No contexto educacional, a avaliação de questões discursivas é um tópico da \textit{Computer-Assisted Asssessment} (CAA) \cite{bogarin2018}, combinando a profundidade textual das técnicas de Processamento de Linguagem Natural (NLP) com a relação entre o conteúdo e as categorias da Classificação de Documentos. Nesta linha de estudo existe a complexidade em identificar a relevância do conteúdo textual para atribuição de notas e produção de feedbacks. Em outra perspectiva desse problema, ainda temos o alinhamento da expectativa de nota do professor com seu padrão avaliativo. Então, a nota ideal envolve o reconhecimento do conteúdo relevante e a forma que o professor atribui nota para o mesmo. 

A avaliação é uma etapa fundamental para o ensino, inclusive para garantir a eficiência dos processos de ensino-aprendizagem. Através do método avaliativo o professor mensura a proficiência dos alunos no conteúdo ministrado. A proficiência envolve avaliar o raciocínio segundo a capacidade de resolver problemas, tomar decisões e realizar inferências sobre o assunto \cite{casiraghi2017}. O papel da avaliação, portanto, é diagnosticar, apreciar e verificar o aprendizado dos alunos para que o professor atue no processo de formação de modo a consolidar seu método de ensino \cite{oliveira2005}. Portanto, por meio das avaliações, o professor observa o progresso dos alunos ao assimilar os conteúdos. A aplicação destas permite ao professor interagir com os materiais pedagógicos junto aos alunos para reformulação e aperfeiçoamento da dinâmica de ensino. Assim, é com o acompanhamento da disciplina e o apoio ao educando que as atividades estabelecem meios de reformular e controlar o processo de ensino-aprendizagem \cite{barreira2006}.

Através da avaliação ocorre a identificação dos \textit{gaps} de aprendizado. Estes \textit{gaps} e as ações para contorná-los tornam a estrutura curricular personalizada, com a turma assimilando os temas de acordo com os objetivos da disciplina \cite{biggs1998}. Portanto, os materiais avaliativos são uma forma de consolidar a aprendizagem, indicando quantos alunos assimilaram os principais temas da disciplina. Com o aumento do número de salas de aula por professor e a popularização dos \textit{Massive Open Online Courses} - MOOCs, a verificação de aprendizagem demandou de apoio computacional para além do acesso ao conteúdo. 

Com a mediação tecnológica, se consolidou a aplicação das atividades em maior escala. Deste modo, os Ambientes Virtuais de Aprendizagem (AVA) \cite{maquine2020} se tornaram plataformas de suporte das aulas para turmas presenciais e a distância \cite{raes2020}. A adoção da tecnologia nos métodos de ensino ampliou o acesso e controle dos materiais, tornando possível a redução da sobrecarga de trabalho dos professores \cite{dunlap2005}. Com isso, o professor ganha também suporte na criação, avaliação, recomendação e visualização de dados educacionais impactando diretamente no acompanhamento do currículo do aluno \cite{paiva2012}. Deste modo, com as ferramentas de apoio que o tutor verifica a aptidão dos estudantes, de forma individual ou coletiva, para melhorar a adaptação e a experiência da disciplina.

Nesse âmbito, as questões discursivas incluem vários tipos textuais, das questões de preenchimento até longas redações. Neste trabalho, entretanto, enfatizamos o suporte ao professor na avaliação de respostas discursivas curtas. Ainda assim, com \textit{datasets} de diferentes características de resposta e avaliação, definimos como respostas curtas conjuntos textuais de até 3 sentenças, compostos por até 100 palavras. Para caracterizar as respostas discursivas curtas apresentamos na Tabela \ref{tab-ptasag46-exemplo} a atividade de exemplo \textit{PTASAG-46}.

\begin{table}[!b]
\centering
\caption{Exemplo de respostas curtas com amostras da atividade 46 do \textit{dataset PTASAG}.}
\label{tab-ptasag46-exemplo}
\begin{tabular}{ r | p{12cm}}
\hline
\multicolumn{2}{l}{\textbf{PTASAG}} \\ \hline
\multicolumn{2}{c}{\textbf{Atividade 46}} \\ \hline 
\multicolumn{2}{l}{\textit{Quais são as diferenças entre veias e artérias?}} \\ \hline
 \# & Resposta \\ \hline
 4 & veias são meio que canos que levam o sangue aos orgãos enquanto as artérias são os canos que levam o sangue ao coração \\
 8 & Veias: sao mais finas. Artéria: são mais grossas \\
 14 & As veias levam o sangue sem oxigênio e as artérias levam o com oxigênio \\
 31 & As artérias tem a função de eliminar o sangue sujo enquanto as veias fazem o contrário \\
 49 & As veias carregam o gás carbônico. As artérias carregam o oxigênio \\
 61 & Artéria passa ar e na veia passa sangue \\
 74  & As artérias bombeam o sangue para todo o corpo e as veias levam o sangue de volta ao coração \\
 144 & Veias passam sangue pouco oxigenado e artérias passam o sangue mais oxigenado. \\
 154 & Veia transporta gás carbônico e artéria o gás oxigênio. \\
 161 & as artérias circulam o ar e as veias circulam o sangue. \\
 211 & A diferença é a valvula \\
 296 & Veias: é um vaso sanguíneo que transporta o sangue em direção ao coração. Artérias: Vasos sanguíneos que carregam sangue do coração para todas as partes do corpo. \\
 451 & Veias: sangue venoso. Artéria: sangue arterial. \\
 520 & A veia é fina já a artéria é grossa pois faz as trocas e leva sangue para o coração \\ 
 570 &  Artérias são mais grossas e são maiores, possuem maior fluxo de sangue e passa gases como O2 e CO2, já as veias são mais finas tem menor fluxo, mas também passa O2 e CO2 \\
\\
\hline
\hline
\end{tabular}
\end{table}


A Tabela \ref{tab-ptasag46-exemplo} apresenta uma pequena amostra de respostas com os devidos indentificadores dos estudantes. Essas amostras foram dadas para a questão \textit{PTASAG-46}, cujo enunciado é ``Quais são as diferenças entre veias e artérias?''. Essa questão será utilizada como forma de ilustrar as questões discursivas curtas. Como as amostras destacam, nesta questão temos respostas de diferentes tamanhos, direções de resposta e desenvolvimento. Entretanto, como o próprio exemplo indica, os \textit{datasets} são característicos pela liberdade de escrita e diversidade de conteúdos. A liberdade de escrita é a base das questões abertas, ou seja, há livre produção textual por parte do estudante. Assim, a escrita aberta é expressa pelas diferentes formas que os estudantes se referem a um ou mais modelos de resposta. Por conta desse fator, a avaliação leva em conta as respostas como representações de conteúdo e o mapeamento dos conceitos, demonstrando as perspectivas de cada um dos participantes sobre o método avaliativo. Nesse contexto, conforme a resposta esperada do professor, uma resposta consistente deve indicar a condução do sangue entre tecidos e o coração para limpeza de toxinas. Em destaque, segue o texto completo: 

\begin{quote}
\textit{Quando o coração bombeia o sangue, ele bombeia este sangue diretamente nas artérias com grande pressão, para que as artérias possam conduzir o sangue na direção dos tecidos. As veias são responsáveis por conduzir o sangue de volta ao coração e removem as toxinas dos tecidos para elas sejam eliminadas.}
\end{quote}

Fica evidente no texto elaborado pelo professor que a essência da resposta deve, pelo menos, tangenciar fatores como a troca do oxigênio e os ciclos de transferência do sangue entre coração e corpo. Portanto, os estudantes recebem a nota máxima ao vincularem corretamente os ciclos arteriais e venosos. Isso ocorre pois, na aplicação de questões discursivas curtas, existe uma expectativa de convergência entre respostas. Essa convergência têm vínculo direto com os enunciados que proporcionam uma ou poucas trilhas de resposta. Essa convegência não é necessariamente para uma simetria entre palavras, como limitante da liberdade textual característica das respostas abertas. Na verdade, essa convergência designa tendência para respostas impessoais e relacionadas diretamente com a temática. As respostas impessoais são caracterizadas pela ausência de marcas pessoais, sendo diretas quanto a expectativa dado o que está descrito no enunciado. Na construção, o estudante deve seguir uma das trilhas do tópico abordado, caso contrário não atende essa expectativa de resposta.


Neste ponto é importante a definição de quatro níveis diferentes interpretativos das questões. São eles: os \textit{modelos de resposta}, a \textit{expectativa de resposta}, as \textit{respostas candidatas} e, por fim, os \textit{padrões de resposta}. 

Segundo as trilhas de resposta seguindo um tópico, podemos inferir que existem modelos que associam o tema abordado com o documento de resposta. Então, chamamos de \textit{modelos de resposta} a convergência entre o que está na resposta com o tema. Descrevemos então \textit{modelo de respostas} como a tendência de determinados conjuntos de resposta de estudantes apresentarem entre si certo índice de similaridade.

Com a existência de modelos objetivos que vinculam respostas correspondentes, podemos afirmar também que a avaliação segue uma \textit{expectativa de resposta} do avaliador. Através desse índice de similaridade, afirmamos que existe um nível de atingimento de resposta que permite a gradação em diferentes níveis de nota. Portanto, o atendimento da \textit{expectativa de resposta} denota quais são as características relevantes que levam a diferentes níveis de avaliação. Portanto, é a \textit{expectativa de resposta} que compõe o alinhamento entre o texto dos estudantes, o tema e as notas atribuídas. Assim, respostas que seguem um mesmo padrão, ou modelo, devem receber notas equivalentes caso nenhum fator externo esteja envolvido no processo avaliativo. Podemos citar como exemplo de um fator externo de avaliação os casos de plágio. Então, isso garante que, nas devidas proporções, os estudantes que seguem uma mesma linha de resposta recebam avaliações similares.

A partir da \textit{expectativa de resposta} com a definição dos conteúdos que diferenciam e determinam as faixas de nota, podemos determinar \textit{respostas candidatas}. As \textit{respostas candidatas} são aquelas produzidas pelo próprio professor como uma definição da \textit{expectativa de resposta} de acordo com o que está disposto no enunciado da atividade. Portanto, são estas que caracterizam a avaliação em um exemplo textual, tal qual o que foi produzido pelos estudantes. Estas determinam o que compõe uma resposta completa para a questão na visão do avaliador, como um referencial. O critério avaliativo e a \textit{resposta candidata} não são determinísticos quando existe algum nível de subjetividade textual, gerando divergência entre avaliadores especialistas \cite{pado2021}.

Nestes três níveis, envolvem-se diretamente a construção textual do aluno e do professor no critério avaliativo para a formação implícita de um modelo. Entretanto, com a adição de sistemas de apoio ao método avaliativo do professor adicionamos mais um nível analítico. Sob a perspectiva do sistema temos os \textit{padrões de resposta}, que são indicam o reconhecimento contextual e lingístico das respostas. Nesse nível, o sistema realiza a análise da questão de forma horizontal, para extrair o que é relevante no critério avaliativo e se aproximar do que é a \textit{expectativa de resposta}. Ao se aproximar do que é a expectativa do avaliador o sistema compreende o vínculo entre notas e as partículas textuais que compõe os \textit{modelos de resposta}. Assim, os \textit{padrões de resposta} são compostos pela correspondência entre respostas e notas, simplificando-os para critérios objetivos.

Com essas quatro perspectivas sobre o conjunto de respostas, designamos as formas com a qual cada entidade participante do processo avaliativo observa a diversidade textual. Portanto, na visão dos estudantes, temos a convergência das respostas na formação de \textit{modelos}. Na análise do professor, os modelos têm viés avaliativo, e esse viés é representado através da \textit{expectativa de resposta}. Por outro lado, quando disponíveis, as \textit{respostas candidatas} atuam para reduzir o nível de abstração da resposta esperada pelo avaliador, apresentando-a via exemplos.  E, por fim, na ótica do sistema, a equivalência entre as estruturas textuais indicam \textit{padrões}, formados por grupos de resposta com as mesmas características.

O processo avaliativo é por definição algo complexo, principalmente pela relação entre os documentos textuais e a nota atribuída. O processo inclui analisar, em detalhes, todo conteúdo com atribuição de notas, produção de \textit{feedbacks} contextualizados e revisão do conteúdos. Neste ainda enfatizamos a diversidade textual. A diversidade textual inclui as diferentes formas de linguagem adotadas para produção das respostas. Isso inclui as variações do atingimento do critério avaliativo. Assim a automação do processo de análise textual, mesmo que parcial, inclui compreender as tendências de resposta de acordo com o conteúdo abordado. 

Pelo caráter multidisciplinar, as respostas curtas são analisadas para além da produção textual, também pela sua completude e direcionamento ao tema. Assim, o aluno é avaliado pela coerência da resposta segundo o tema, pela capacidade de sumarização e pela aplicação da linguagem. O papel do sistema inclui, portanto, aspectos fundamentais da linguagem, a correspondência com o conteúdo ministrado e a capacidade de reconhecer dos padrões de escrita. Com essa perspectiva, o objetivo geral dos sistemas de CAA é reduzir o esforço avaliativo do professor no papel de avaliação contribuindo com a análise da diversidade textual. Para isso, os sistemas devem criar modelos linguísticos robustos, de forma a ter alto nível de interpretação textual.

O reconhecimento das estruturas que formam a linguagem escrita são fundamentais para a descoberta dos \textit{padrões de resposta}. Cada resposta, como um documento textual, é composta por uma série de características. Cada característica é extraída de acordo com a construção da estrutura textual, seja ela no aspecto gramatical, morfológico, semântico, sintático, estatístico ou sequencial \cite{kumar2019}. Portanto, o reconhecimento de padrões passa pela identificação das características mais relevantes nas respostas que compõe a avaliação de uma atividade. A quantidade de características em média extraídas por atividade nos \textit{datasets} utilizados neste trabalho são apresentados na  Tabela \ref{tab-features}.

% TABELA CARACTERISTICAS
\begin{table}
\centering
\caption{Média de observados nas respostas }
\label{tab-features}
\begin{tabular}{|r | r r r|} \hline
\textit{Dataset} & Características & Palavras & Caracteres \\
\hline
UNT & 140 & 20 & 107 \\
ASAP & 2932 & 43 & 236 \\
Beetle & 98 & 10 & 50 \\
Open University & 418 & 10 & 55 \\
Findes & 123 & 8 & 40 \\
Powergrading & 178 & 4 & 20 \\
PTASAG & 906 & 13 & 72 \\
SEB & 110 & 13 & 64 \\
VestUFES & 1391 & 92 & 536 \\
\hline \hline
\end{tabular}
\end{table}

Como a Tabela \ref{tab-features} destaca, mesmo sobre um tipo específico de questão, temos variações importantes no modelo de resposta. Apesar de todos os conjuntos se enquadrarem nas especificações de respostas com menos de 100 palavras ou 3 sentenças, são evidentes as diferenças entre \textit{datasets}. Enquanto majoritariamente temos conjuntos com respostas bem concisas (menores que 20 palavras), temos VestUFES e ASAP mais descritivos e, possívelmente, com enunciados mais abstratos. Diante do escopo delimitado para as respostas, sobressaem alguns desafios na compreensão computacional da linguagem e dos métodos avaliativos. Deste modo, é fundamental a produção de modelos avaliativos computacionais que demonstrem fluência na análise da linguagem e conteúdo. Portanto, o sistema é composto por modelos avaliativos e devem se aproximar ao máximo do critério do professor ao realizar inferências.

Sabendo dos desafios de uma aplicação em CAA, porpomos um modelo de \textit{Active Learning} com análise das estruturas que compõe o texto em uma aplicação de reconhecimento de padrões. Utilizamos técnicas de \textit{Active Learning} combinando \textit{Unsupervised} e \textit{ Supervised Learning}. O primeiro é aplicado para identificação da distribuição espacial e amostragem. Enquanto isso, o segundo atua na construção de avaliadores alinhados ao reconhecimento de padrões textuais. Assim, o sistema chamado \textit{p}Nota, apresenta uma combinação de técnicas de pré-processamento, clusterização, amostragem, classificação e produção de \textit{feedbacks} para criar um modelo consistente em relação a critério avaliativo do professor.

Sendo a atribuição de notas vinculada diretamente ao critério do professor, as respostas são comparadas diante de sua similaridade em diferentes técnicas de classificação ou regressão. A técnica depende diretamente do formato da nota. O modelo de avaliação de respostas discursivas curtas (ou \textit{Short Answer Graders} (SAG) têm três papeis principais. O primeiro papel é a identificação dos padrões de resposta. O segundo é reproduzir o critério avaliativo do professor através de sua técnica de avaliação. Por fim, o terceiro compõe a descrição do método, com a criação de \textit{feedbacks} para todos os participantes \cite{arter2006, spalenza2016a}.


\section{Problema} 
\label{cap1-problema}

Dentre a literatura dos SAG, encontramos uma série de problemas que caracterizam a evolução da pesquisa durante os anos. Em geral, a característica principal destes é a relação entre conteúdo textual e a atribuição de nota, nem sempre de forma objetiva. Com isso, os avaliadores devem aprender o método do professor como especialista, identificando padrões de resposta que levam a cada uma das categorias de nota. Assim, além de compreender a linguagem, os modelos precisam identificar o vínculo de cada resposta com o tema da questão. Nessa linha, a expectativa é a criação de modelos SAG cada vez mais similares ao formato de avaliação do professor. Portanto, com forte aderência aos desafios de NLP, os SAG buscam aprimorar os modelos avaliativos para conseguir avaliações cada vez mais adequadas ao critério do professor \cite{pado2021}. Mesmo sendo um trabalho realizado há decadas \cite{burrows2015}, a literatura dos modelos SAG descreve uma série de problemas em aberto que foram pouco estudadas até o momento.

Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto na forma bruta \cite{perez-marin2009}. Nestes, a atribuição de notas é dada pela compatibilidade exata entre texto e chave de resposta. São modelos sem flexibilidade e resolvem apenas problemas simples. Essa linha de trabalho falhou por inúmeras vezes na padronização e identificação de sinônimos \cite{leffa2003}. Problemas similares aconteceram com as técnicas que usavam apenas as métricas de resposta, como a quantidade de palavras ou frases que cada resposta contém. Porém, essas linhas de trabalho que identificaram \textit{gaps} importantes na análise de conhecimento contextual e na formulação individual das respostas. Por conta disso, a robustez da análise é parte fundamental de boa parte dos algoritmos atuais em SAG \cite{filighera2020}.

Posteriormente, os sistemas ganharam um pouco de flexibilidade textual com extração de informação e expressões regulares. Porém, mesmo esses sistemas falham para identificar a paridade dos termos dentro da linguagem e na adaptação em diferentes contextos. Atualmente a área já avalia o texto de forma mais robusta, combinando NLP e ML. Nos últimos 5 anos também começaram a figurar alguns estudos comparativos, adotando técnicas de \textit{Deep Learning} \cite{bonthu2021}. Porém, até o momento há preocupação com a profundidade do aprendizado, em tradução literal para ``\textit{depth of learning}'' \cite{burrows2015}. A profundidade indica a capacidade de recuperar a informação do texto e atuar na atribuição de notas segundo o contexto. Portanto, esta é característica dos modelos SAG que define a produção de modelos complexos de correção, interpretando computacionalmente o conteúdo de respostas curtas em textos de escrita livre.

Diretamente associada à interpretação textual, existe a busca de convergência entre as respostas. Nesse aspecto há o problema para extração do viés de resposta em respostas factuais com múltiplos contextos. Além disso, existe ainda maior complexidade para lidar com questões que resultam em respostas opinativas, individuais ou subjetivas \cite{bailey2008}. Aliado à isso, é esperado que o sistema, de forma independente do conteúdo do professor, lide com a liberdade de escrita do estudante e analize a convergência entre respostas na tentativa de recuperar padrões compatíveis \cite{saha2018, lui2022}.

Em geral, para além do reconhecimento de padrões de resposta, ainda existe o alinhamento entre o conteúdo das respostas e o critério avaliativo. De forma geral, esse fator é um reflexo das referências utilizadas na criação do modelo avaliativo \cite{krithika2015}. Para compreender o papel do especialista, o sistema deve seguir o professor em seu padrão de avaliação, tentando replicá-lo \cite{jordan2012, funayama2020}. Um exemplo da divergência entre modelos de resposta e modelos de avaliação acontece quando o professor avalia negativamente respostas que ele determina como plágios. Nessa situação, é complexo ao sistema se adaptar para respostas que tem o alinhamento correto de resposta mas que recebem uma distinção nas notas. Assim, apesar da escolha de palavras alinhadas com um determinado modelo de resposta, é essencial que o sistema forme vínculos entre padrões de avaliação e de respostas para criação de modelos avaliativos robustos \cite{higgins2014}. Nesse aspecto, destacamos que é fundamental a extração do critério avaliativo do professor, para além de um sistema tradicional de reconhecimento de padrões.

Ainda sobre a expressão da nota atribuida para cada resposta, existe também a preocupação com classificações incorretas. Em todas as formas, é fundamental que a atribuição de notas seja coerente e justificável, em especial na adoção dos SAG \cite{funayama2020}. Assim, é recorrente o uso de formas que remontam as componentes de resposta que levam a uma correção, seja via regras de associação, expressões regulares ou a extração de características textuais \cite{chakraborty2017, kumar2019}. Nessa linha, é essencial que os sistemas compreendam o conteúdo sem avaliações tendenciosas \cite{azad2020}, realizando uma análise ampla do conteúdo anotado.

Aliado a isso, para a garantia da isonomia no processo avaliativo, devemos identificar quando tais incoerências ocorrerem. Existem níveis de erro tanto durante a aplicação do modelo de avaliação quanto na anotação de respostas, algo comum até entre dois especialistas \cite{artstein2008, pado2021}. Mas é essencial minorar a diferença cada vez mais entre o modelo do especialista e o modelo de avaliação automática \cite{condor2020}. Para além da necessidade de justificativa a cada nota atribuída, ainda ressaltamos a necessidade de reconhecer \textit{outliers} \cite{ding2020} e garantir que este não se torne infuente ao método avaliativo. Nessa dinâmica, ressaltamos a importância em isolar comportamentos anômalos do método avaliativo para que não influencie no comportamento geral do modelo automático.

Sabendo disso, um critério avaliativo robusto deve ponderar quais componentes textuais compõe o modelo de avaliação. A aquisição desse modelo é feita através da identificação do formato avaliativo do professor em uma série de respostas. Ainda adicionamos a isso, o desbalanceamento entre os níveis de nota e a baixa amostragem \cite{dzikovska2012, lui2022}. Assim, a primeira aplicação de uma atividade geralmente produz bases de dados com pequena quantidade de amostras e com grande diferença dentro dos grupos de nota. Por conta disso, uma série de trabalhos faz uso de descritores do padrão avaliativo, como as expressões regulares, regras ou quadros de \textit{rubrics}, para interpretar a forma que o professor constrói seu padrão de avaliação \cite{butcher2010, mohler2011, ramachandran2015a, condor2021}. Porém, isso contrapõe a proposta de reduzir o esforço avaliativo do professor, se considerarmos a necessidade de produção de qualquer conteúdo extra sobre a avaliação \cite{zesch2015, horbach2018}. É importante, portanto, a melhoria das técnicas de aprendizado, amplificando a aquisição de conhecimento pelos exemplos. Através dessa melhoria que priorizamos o esforço já aplicado na anotação para remontar o critério avaliativo.

Um contraponto ao aprendizado por exemplos é lidar com a amplitude da linguagem durante a atribuição de notas. Isso acontece porque os padrões desconhecidos podem conter \textit{outliers} que recebem um modelo próprio de avaliação \cite{filighera2020}. Isso significa que, dado nível de subjetividade da questão e a diversidade textual, o modelo deve aprender formas de avaliar padrões não mapeados. Assim, a seleção de amostras é fundamental para conectar a diversidade textual aos níveis de nota. Isso torna necessário aos sistemas a análise da distribuição de amostras e a anotação guiada das respostas, conectando o tópico abordado nos documentos textuais ao critério avaliativo \cite{marvaniya2018}.

Como consequência da representação textual das notas, na esfera avaliativa, temos um problema na criação de modelos complexos entre termos e classes \cite{ramachandran2015a}. Sendo a nota de vínculo interpretativo, em aspectos gerais, podemos dizer que existe apenas a aproximação ou similaridade entre as formas de avaliação. A similaridade indica que os especialistas concordam e seguem as mesmas diretrizes na atribuição das notas \cite{artstein2008}. Por outro lado, isso significa também que cada especialista pode ter análises individuais do conjunto de respostas. Então, é característica de um avaliador, em especial nos modelo SAG, compreender e incorporar detalhes sutis do texto em seu critério de avaliação \cite{horbach2018, condor2021}. Portanto, a relação termo-classe deve ser dinâmica e extrair o modelo que melhor atenda às expectativas do professor, em especial com o fato da mesma ser passível de revisões \cite{spalenza2016a}.

Quando olhamos o conjunto de respostas, é fundamental partir da sua formação por aspectos estruturais. Por consequência, além da análise detalhada do modelo textual, é fundamental uma extensa capacidade analítica do conteúdo \cite{saha2018}. Isso significa que, além do nível textual é desejável que a análise seja feita em vários níveis, incluindo verificação morfológica, semântica e sintática de cada resposta \cite{sakaguchi2015, riordan2019, sahu2020}. Deste modo, a aquisição de informação do texto deve maximizar o conhecimento na formação dos modelos, para compreensão do tema e da estrutura de escrita. Somado a isso, algumas propostas vão além e ainda exploram a conexão semântica entre respostas, questões e domínios \cite{dzikovska2013, saha2019}.

A confiabilidade dos SAG também é constituida pela soma dos fatores aqui elencados. Superficialmente podemos associar este problema a divergência de notas entre avaliadores. Porém, em um aspecto amplo, a confiabilidade do sistema inclui desde o reconhecimento do critério avaliativo até a criação de justificativas de nota através de modelos descritivos de \textit{feedback} \cite{kumar2019}. O papel dos modelos de \textit{feedback} vai além de descrever o que o sistema observou na avaliação. Este declara a todos os participantes a relação entre as respostas, o reconhecimento do critério de avaliativo e cada anotação do professor \cite{marvaniya2018, bernius2022}. Portanto, a confiabilidade do sistema passa por todos os níveis citados de representação do conhecimento.

Por fim, ainda existem complicações para encontrar datasets públicos na literatura \cite{burrows2015}. Além disso, os poucos disponíveis têm métricas específicas de comparação, apresentando problemas ao estabelecer paridade de cada sistema com a literatura. Aumentando a dificuldade de replicar o que foi realizado nos demais estudos. Deste modo, em SAG uma base de dados adequada deve simular o processo avaliativo do professor, dando visibilidade para comparações e resultados encontrados na literatura.


\section{Proposta}
\label{cap1-proposta}

Conforme os relatos encontrados na literatura dos SAG, apresentamos neste trabalho um sistema que propõe uma análise das estruturas textuais para produção dos modelos avaliativos complexos mencionados. Portanto, temos uma proposta que atende várias deficiências dos SAG. Cada um destes problemas é detalhadamente descrito anteriormente, na Seção \ref{cap1-problema}. Portanto, a ideia é desenvolver um método de reconhecimento do critério do professor através da avaliação das estruturas textuais, estabelecendo relações entre as respostas e suas respectivas notas.

Para atender as demandas encontradas nos trabalhos em SAG utilizamos de técnicas clássicas de \textit{Educational Data Mining} (EDM) \cite{romero2010}. Apesar do método ter fundamento em modelos linguísticos complexos e comportar questões em diversas linguagens, a avaliação conta com as principais bases de dados em \textit{inglês} e \textit{português} da literatura. Nestes \textit{datasets} observamos 3 tipos de avaliações: notas ordinais, notas discretas e notas contínuas \cite{morettin2010}. Portanto, neste trabalho, estudamos estruturas para identificação das principais respostas do conjunto, reconhecimento do método avaliativo do professor (especialista) e elaboração \textit{feedbacks}.

Para identificação das principais respostas apresentamos um modelo de \textit{Active Learning}. Em \textit{Active Learning} o especialista ativamente passa o conhecimento para o algoritmo de classificação \cite{silva2007, miller2020}. O algoritmo, por sua vez, utiliza o as informações passadas para criar um modelo que replica o especialista na tarefa. Neste caso, o professor ensina ao sistema seu método avaliativo e, através da atribuição de notas, é formado um modelo que realiza as avaliações das demais atividae \cite{romero2010}. Cada uma das respostas enviadas para atividade é considerada uma amostra para o sistema. Dentre todas as amostras, é fundamental que o sistema aprenda em detalhes as diferentes características encontradas nas respostas, identificando sua representatividade. Para essa seleção o sistema combina técnicas de otimização e clusterização \cite{everitt2011, spalenza2019}. As respostas selecionadas são denominadas de treinamento, pois serão utilizadas para produção dos modelos, enquanto as demais formam o conjunto de teste. O conjunto de teste determina o desempenho do sistema como avaliador.

No reconhecimento do método avaliativo do professor, modelos são criados visando a atribuição de notas para respostas discursivas. Essa etapa de classificação deve se aproximar ao máximo da tarefa realizada pelo professor, analisando a similaridade entre as respostas. Quanto menor a diferença entre a nota dada pelo sistema e a nota atribuída pelo professor, melhor o modelo criado. Consequentemente, os melhores modelos representam com coerência a diversidade de notas e respostas, apresentando menor índice de erros. Na gradação das notas, quanto maior a discrepância entre as notas mais críticos são os erros. Destacamos ainda que mesmo entre humanos especialistas existe esse nível de erro \cite{artstein2008, pado2021}. Os dados selecionados para treino do classificador ditam o conhecimento da gradação de notas distribuídas por ele. Portanto, o classificador recebe as características de cada resposta e a sua respectiva avaliação e as compara com as amostras de teste, com notas não conhecidas. Portanto, o modelo de classificação, tomado aqui como avaliador, produz as notas complementares para o conjunto de dados de teste.

Por fim, a elaboração de \textit{feedbacks} é fundamental para o suporte ao professor, com a descrição do método avaliativo e sumarização dos resultados. Em sala de aula, os \textit{feedbacks} são um material que detalha a avaliação para professores e alunos, de forma a sanar dúvidas e evidenciar \textit{gaps} no aprendizado. Por outro lado, na perspectiva da interação do professor com o sistema, os \textit{feedbacks} caracterizam a decisão, descrevem o modelo textual e a equivalência entre respostas \cite{bernius2022}. Portanto, em aspectos gerais, todos os ciclos do sistema atuam para reduzir o esforço de correção do tutor, apresentar resultados de alto nível com o modelo avaliativo e gerar materiais complementares explicativos sobre as notas atribuidas.

\section{Objetivos} \label{cap1-objetivos}

O objetivo deste trabalho é reduzir gradativamente o esforço de correção do professor através de um modelo de avaliação de respostas discursivas curtas. Para isso, é essencial o aprendizado do critério avaliativo do professor através de exemplos, reduzindo o esforço necessário em mais aplicações do mesmo conjunto de respostas. Assim, esperamos criar modelos avaliativos que compreendam as estruturas de linguagem, o alinhamento ao tópico de cada resposta e a forma com a qual é feita a atribuição de notas pelo especialista. Desta forma, através do \textit{p}Nota, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor para concentrar-se na verificação de aprendizagem do aluno.

Portanto, temos como âmbito principal aprender o comportamento avaliativo que vincula uma nota para determinadas as estruturas textuais que compõe as respostas dos estudantes. Para isso, esperamos reproduzir por meio do SAG \textit{p}Nota padrões avaliativos complexos, sendo um avaliador similar ao professor.

Para isso, estudamos as diferentes formas de construção de respostas discursivas curtas, a identificação de componentes relevantes e a representação do conhecimento em questões discursivas curtas. Nesta linha, para atingir o objetivo geral descrevemos os seguintes objetivos específicos:

\begin{itemize}
\item Organizar os \textit{datasets} públicos da literatura para estabelecer uma comparação com resultados obtidos em estudos correlatos \cite{burrows2015};
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma gramatical, morfológica, semântica, sintática, estatística ou sequencial \cite{galhardi2018a, kumar2019, sahu2020};
\item Interpretar minuciosamente as respostas e o alinhamento do conteúdo, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{jordan2012, saha2018, ding2020};
\item Elaborar e ajustar a avaliação de forma eficiente, assimilando o critério estabelecido pelo professor \cite{zesch2015, condor2020, lui2022};
\item Criar modelos avaliativos robustos, associando as categorias de nota aos padrões textuais \cite{butcher2010, heilman2015, burrows2015};
\item Identificar estruturas textuais para cada categoria de nota, removendo \textit{outliers} e controlando da consistência da classificação \cite{ding2020, filighera2020};
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{higgins2014, funayama2020, pado2021};
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{mizumoto2019, suzen2020, bernius2022}.
\end{itemize}

\section{Estrutura do Trabalho}

A seguir são apresentados os conteúdos dessa tese. A proposta é discutida em detalhes através de 5 capítulos. Para além da Introdução, o trabalho é composto dos seguintes capítulos:

\begin{itemize}
\item \textbf{Capítulo \ref{cap-literatura} - Revisão de Literatura:} Apresenta uma breve revisão da literatura sobre métodos de análise e avaliação de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-metodo} - Método:} Define a estrutura do sistema \textit{p}Nota e as formas utilizadas para efetuar de maneira abrangente a análise de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-experimentos} - Experimentos e Resultados:} Descreve por meio de nove \textit{datasets} as diferentes formas de apoio avaliativo, modelagem da relação termo-nota e a formação de \textit{feedbacks} utilizados pelo sistema.

\item \textbf{Capítulo \ref{cap-conclusao} - Conclusão:} Discute as contribuições deste trabalho, conclusões extraídas dos resultados obtidos e as perspectivas de trabalhos futuros.

\end{itemize}