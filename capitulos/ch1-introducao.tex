% ==============================================================================
% TCC - Nome do Aluno
% Capítulo 1 - Introdução
% ==============================================================================
\chapter{Introdução}
\label{cap1-intro}

A avaliação é uma etapa fundamental para o ensino, inclusive para garantir a eficiência dos processos de ensino-aprendizagem. Através do método avaliativo que o professor mensura a assimilação do conteúdo ministrado. Portanto, é por meio das avaliações que o professor observa o desempenho da turma e seu progresso nos conteúdos. Nesse aspecto, é fundamental que o professor verifique com frequência o aprendizado dos estudantes no decorrer da disciplina. Assim, essa aplicação permite ao professor interagir com os alunos junto com os materiais pedagógicos para reformulação e aperfeiçoamento da dinâmica de ensino. Deste modo, é com o acompanhamento da disciplina e o apoio ao educando que as atividades estabelecem meios de reformular e controlar o processo de ensino-aprendizagem \cite{barreira2006}.


Através das atividades, somada ao acompanhamento em sala, avaliamos a proficiência dos estudantes sobre determinado domínio. A proficiência envolve avaliar o raciocínio segundo a capacidade de resolver problemas, tomar decisões e realizar inferências sobre o assunto \cite{casiraghi2017}. O papel da avaliação, portanto, é diagnosticar, apreciar e verificar o aprendizado dos alunos para que o professor atue no processo de formação de modo a consolidar seu método de ensino \cite{oliveira2005}. Deste modo, além do desenvolvimento e da sequência de métodos avaliativos, são imprescindíveis a verificação dos resultados e a correção de problemas nos métodos de ensino-aprendizagem.


O método avaliativo é o que torna possível o acompanamento e a solução dos problemas com o aprendizado dos alunos. Essa identificação de problemas e as ações para contorná-los tornam a estrutura curricular personalizada, alinhando a turma de acordo com os objetivos da disciplina \cite{biggs1998}. Portanto, é através das atividades que criamos o modelo para mensurar o conhecimento individual dos alunos. Para isso, a mediação tecnológica consolidou-se para aplicação das atividades em quantidade e qualidade. Deste modo, os Ambientes Virtuais de Aprendizagem (AVA) \cite{maquine2020} se tornaram modelos virtuais para suporte das aulas para turmas presenciais e a distância \cite{raes2020}. Com a mediação tecnológica, apoiamos o professor na criação, avaliação, recomendação e visualização de dados educacionais impactando diretamente no acompanhamento do currículo do aluno \cite{paiva2012}. Deste modo, é com as ferramentas de apoio que o tutor verifica a aptidão dos estudantes, de forma individual ou coletiva, para melhorar a adaptação e a experiência da disciplina.

Nesse ponto, o acompanhamento, a formulação, a aplicação e os resultados dos métodos avaliativos em meio computacional são estudados pela área de \textit{Computer-Assisted Asssessment} (CAA) \cite{bogarin2018}, ou em tradução literal Avaliação Assistida por Computadores. Na literatura de CAA, existe uma extensa pesquisa por métodos avaliativos e sua aplicação de forma digital \cite{perez-marin2009}. Em especial, destacamos as questões discursivas curtas, fundamentais para o desenvolvimento da escrita para aplicação em ampla escala neste formato. A avaliação de questões discursivas é dispendiosa, demandando análises da relação de cada resposta com seu alinhamento com o tema. Portanto, o estudo de formas computacionais para suporte aos métodos de avaliação de respostas discursivas, garantem maior capacidade de aplicação e correção para mensurar o aprendizado.

Nesse aspecto, sabendo que existe um critério formulado pelo professor para correção das respostas discursivas, propomos uma abordagem através da análise das estruturas textuais para reconhecimento de padrões. Assim, neste trabalho descrevemos o \textit{p}Nota, um modelo semi-supervisionado para identificação do método avaliativo, extração de padrões textuais, classificação da base de dados e produção de \textit{feedbacks}. Considerando a liberdade textual característica das respostas discursivas, verificamos a similaridade entre respostas e os grupos de termos referenciais para atribuir notas de forma equivalente ao avaliador humano. Com os modelos de avaliação de respostas discursivas curtas (ou \textit{Short Answer Graders} - SAG), esperamos identificar modelos de resposta, reproduzir o método avaliativo e criar \textit{feedbacks} descritivos para todos os participantes da disciplina \cite{arter2006, spalenza2016a}.

\section{Problema} 
\label{cap1-problema}

Dentro da literatura dos sistemas SAG, encontramos determinados problemas listados por autores durante os anos de evolução da pesquisa. Os problemas são amplos, onde se busca aprimorar gradativamente os modelos avaliativos para conseguir resultados cada vez mais adequados aos do professor \cite{pado2021}. Assim, buscamos para além da redução do esforço de correção, a ampliação da análise e a proximidade dos modelos avaliativos do especialista e do avaliador automático. Nesse aspecto, apesar de ser um estudo já realizado há décadas, ainda encontramos nos modelos SAG uma série de desafios com demandas importantes e pouco estudadas até o momento.

Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto bruto \cite{perez-marin2009}. A partir disso, a busca por equivalência entre a resposta esperada e o texto dos estudantes falhou por inúmeras vezes na padronização dos documentos e na identificação de sinônimos \cite{leffa2003}. O estudo dessa pesquisa fomentou inúmeras discussões em torno da identificação do conhecimento obtido pelas respostas escritas pelo aluno. A robustez dessa análise é parte fundamental de boa parte dos algoritmos atuais em SAG \cite{filighera2020}.

Na principal revisão da literatura sobre os sistemas SAG \cite{burrows2015}, os autores reúnem 37 trabalhos realizados na área. Durante esse estudo, o autor destaca o problema da  profundidade do aprendizado, em tradução literal para ``\textit{depth of learning}'', separando as atividades em dois grupos: de reconhecimento e de recuperação. No Brasil, conhecemos discriminamos os dois tipos de questão como abertas e fechadas \cite{gunther2012}. Então, é característica dos modelos SAG a produção de modelos complexos de correção de questões de recuperação, interpretando computacionalmente o conteúdo de respostas curtas em textos de escrita livre.

Um problema diretamente associado ao modelo de interpretação textual, entretanto, é a busca de convergência entre as respostas. É uma dificuldade a extração do viés de resposta em questões discursivas factuais com múltiplos contextos. Além disso, existe ainda maior complexidade para lidar com questões que resultam em respostas opinativas, individuais ou subjetivas \cite{bailey2008}. Apesar do conteúdo, é esperado do sistema que, independente do conteúdo recebido do professor, lide com a liberdade de escrita do estudante e analize a convergência entre respostas na tentativa de recuperar padrões compatíveis \cite{saha2018}. 

Em geral, para além do reconhecimento de padrões de resposta, ainda existe o alinhamento entre o conteúdo das respostas e o critério avaliativo. Esse fator se destaca pela referência utilizada na criação do modelo avaliativo \cite{krithika2015}. O professor, no papel de especialista, deve ser seguido segundo seu padrão avaliativo na tentando imitá-lo \cite{jordan2012, funayama2020}. Para ilustrar esse aspecto podemos usar como exemplo a avaliação de plágios de forma negativa. Como é de interesse dos sistemas SAG seguir o modelo avaliativo do professor, mesmo que a essência do conteúdo seja coincidente com respostas próximas, o padrão específico reconhecido negativamente deve receber avaliação equivalente por conta do plágio segundo o método avaliativo do professor. Assim, apesar da escolha de palavras alinhadas com um determinado modelo de resposta, é essencial que o sistema forme vínculos entre padrões de avaliação e de respostas para criação de modelos avaliativos robustos \cite{higgins2014}. Nesse aspecto destacamos que é fundamental para além de um sistema tradicional de reconhecimento de padrões a extração do critério avaliativo do professor.

Sabendo disso, o critério avaliativo deve atrelar componentes textuais ao método avaliativo. A aquisição desse modelo deve ser feita através da identificação da forma que o professor avalia uma série de respostas. Porém, uma série de trabalhos utiliza descritores do padrão avaliativo para representar a forma que o professor interpreta modelos de resposta dentre expressões regulares e regras até o quadro de \textit{rubrics} \cite{butcher2010, mohler2011, ramachandran2015a}. Porém, isso contrapõe a proposta de reduzir o esforço avaliativo do professor, se considerarmos a necessidade de produção de qualquer conteúdo extra sobre a avaliação \cite{zesch2015, horbach2018}. A partir daí para remontar o critério avaliativo do professor, deve priorizar o uso de padrões de avaliação sem requisitar descritores ou chaves de resposta.

Dentro desse aspecto, durante a análise da compatibilidade entre os modelos do sistema \textit{FreeText Author} e do professor \cite{butcher2010}, os autores elencaram seis problemas. O primeiro é a omissão dos padrões de avaliação. O segundo é a identificação da associação entre palavras e a sua conexão com o modelo avaliativo. O terceiro é a necessidade de identificação estrutural da sentença. O quarto é o tratamento de classificações incorretas, em especial por parte do especialista. O quinto é o conflito entre padrões corretos e incorretos. E, por fim, o sexto problema listado pelos autores é diretamente relacionado aos demais, indicando o problema de confiabilidade do sistema como avaliador e a interpretação inconsistente do conteúdo textual.

Na perspectiva da omissão dos padrões avaliativos, detalhamos a diferença entre o sistema ter o conhecimento dos padrões textuais e a avaliação de padrões desconhecidos. Padrões desconhecidos podem ter \textit{outliers} que estritamente recebem um modelo próprio de avaliação \cite{filighera2020}. Entretanto, para além dos métodos aleatórios de amostragem, a avaliação de questões discursivas curtas \textit{a priori} indica um problema de classificação desbalanceada \cite{dzikovska2012}. Deste modo, destacamos a importância dos métodos de anotação direcionada a diversidade textual e uso de métodos de verificação da distribuição das amostras \cite{marvaniya2018}.

O segundo listado, em uma outra esfera avaliativa, estabelece a criação de modelos robustos entre termos e classes \cite{ramachandran2015a}. Portanto, torna-se característico segundo os autores que os modelos SAG devem incorporar detalhes sutis da avaliação \cite{horbach2018}. Portanto, a relação termo-classe deve ser dinâmica e, apesar da avaliação ser passível de revisões e ajustes a qualquer momento, sempre extrair o modelo que melhor atenda às expectativas do professor \cite{spalenza2016a}.

Na sequência, o terceiro problema listado é de aspecto estrutural, observando cada resposta segundo os detalhes de sua construção. Por consequência, além da análise detalhada do modelo textual, é fundamental uma extensa capacidade analítica do conteúdo \cite{saha2018}. Portanto, além do nível textual desejamos que a análise seja feita em vários níveis, incluindo verificação morfológica, semântica e sintática de cada resposta \cite{sakaguchi2015, riordan2019, sahu2020}. Deste modo, incluimos neste aspecto, além de formas de maximizar a aquisição de informações em texto, a análise estrutural para compreensão da escrita das respostas. Somado a isso, algumas abordagens vão além e ainda exploram a conexão semântica entre respostas, questões e domínios \cite{dzikovska2013, saha2019}.

O quarto problema inclui o tratamento de classificações incorretas. É extremamente relevante aos sistemas SAG a construção de justificativas com fundamentos em referências textuais \cite{funayama2020}. Assim, é recorrente a possibilidade de remontar as componentes que levam a correção de cada resposta, sejam regras de associação de respostas, padrões de expressões regulares ou a extração de características textuais \cite{chakraborty2017, kumar2019}. Para além da necessidade de justificativa, para cada nota atribuída, ainda ressaltamos a capacidade de identificar \textit{outliers} \cite{ding2020} e garantir que não se torne uma influência ao método avaliativo. Nessa linha, é importante que os modelos compreendam o conteúdo sem avaliações tendenciosas \cite{azad2020}, realizando uma análise ampla do conteúdo anotado.

De forma contínua ao quarto, o quinto problema compreende a identificação de incoerências nas avaliações. Entretanto, a incoerência é algo esperado desde que a divergência existe mesmo que entre dois humanos especialistas \cite{artstein2008, pado2021}. Mas é essencial minorar a diferença cada vez mais entre o modelo do especialista e o modelo de avaliação automática \cite{condor2020}. Nessa dinâmica, ressaltamos a importância em isolar comportamentos anômalos do método avaliativo para que não influencie no comportamento geral do modelo automático.

Por fim, a confiabilidade do sistema, tangenciando todos os demais citados, é tratada no último item. Superficialmente podemos associar este problema a divergência de notas entre avaliadores. Porém, em um aspecto amplo, a confiabilidade do sistema passa do reconhecimento do critério avaliativo à criação de justificativas de nota através de modelos descritivos de \textit{feedback} \cite{kumar2019}. O papel dos modelos de \textit{feedback} vai além de descrever o que o sistema observou na avaliação. Este declara a todos os participantes a relação entre as respostas, o reconhecimento do critério de avaliativo e cada anotação do professor \cite{marvaniya2018}. Portanto, a confiabilidade do sistema passa por todos os níveis, desde a aquisição de um critério de avaliação coerente até a representação do conhecimento.

Para além disso podemos ainda citar dificuldade em encontrar os \textit{datasets} utilizados por trabalhos da literatura \cite{burrows2015}. É muito comum encontrar trabalhos no qual os autores coletaram dados na própria universidade e não as tornam públicas. Além disso, em SAG uma base de dados adequada deve caracterizar o processo avaliativo do professor e constar com relevantes resultados na literatura. Assim, neste trabalho identificamos, testamos e descrevemos uma série de \textit{datasets} na avaliação do método proposto.

\section{Proposta}
\label{cap1-proposta}

Neste trabalho apresentamos um método de avaliação de respostas discursivas curtas através da análise da estrutura textual para produzir modelos avaliativos complexos. Para seu desenvolvimento, identificamos os problemas mais comuns descritos na literatura como deficiências dos sistemas SAG, apresentando uma proposta de solução. Cada um destes problemas é detalhadamente descrito na Seção \ref{cap1-problema}. Portanto, a ideia é desenvolver uma estrutura de reconhecimento do critério avaliativo do professor estabelecendo a relação entre as respostas e as notas atribuídas.


Para atender as demandas encontradas nos trabalhos em SAG utilizamos de técnicas clássicas de \textit{Educational Data Mining} (EDM) \cite{romero2010}, \textit{Machine Learning} (ML) \cite{han2011} e \textit{Natural Language Processing} (NLP) \cite{jurafsky2009}. Apesar do método ter fundamento em modelos linguísticos complexos e comportar questões em diversas linguagens, o avaliamos nas principais bases de dados em \textit{inglês} e \textit{português} da literatura. Dentre os \textit{datasets} observamos 3 tipos de avaliações: notas ordinais, notas discretas e notas contínuas \cite{morettin2010}. Portanto, neste trabalho, estudamos estruturas para identificação das principais respostas do conjunto, reconhecimento do método avaliativo do professor (especialista) e elaboração \textit{feedbacks}.

Para identificação das principais respostas apresentamos um modelo de aprendizado semi-supervisionado. No aprendizado semi-supervisionado o especialista ativamente passa o conhecimento para o algoritmo de classificação \cite{baeza2011}. O algoritmo, por sua vez, utiliza o as informações passadas para criar um modelo que imite o especialista na tarefa. Neste caso, o professor ensina ao sistema seu método avaliativo e, através da atribuição de notas, é formado um modelo que tenta replicar o método para as demais respostas da atividades \cite{romero2010}. Cada uma das respostas enviadas para atividade é considerada uma amostra para o sistema. Dentre todas as amostras, é fundamental que o sistema aprenda cada uma das características das respostas, selecionando as principais por representatividade. Para essa seleção o sistema utiliza de técnicas de otimização e clusterização \cite{everitt2011}. As respostas selecionadas são denominadas de treinamento, pois serão utilizadas para produção dos modelos, enquanto as demais são o conjunto de teste.

No reconhecimento do método avaliativo do professor, modelos são criados para classificação das respostas discursivas. A categorização deve se aproximar ao máximo da tarefa realizada pelo professor, analisando detalhes parecidos na resposta. Portanto, o modelo avaliativo tem por premissa atender as expectativas do professor \cite{pado2021}. Quanto menor a diferença entre a nota dada pelo sistema e a nota atribuída pelo professor, melhor o modelo criado. Consequentemente, os melhores modelos representam melhor a diversidade de notas e respostas com tendência menor de erros. Na gradação das notas, quanto maior a discrepância entre as notas mais críticos são os erros. Sabendo que, entre avaliadores humanos também existe esse erro \cite{artstein2008}. Os dados selecionados para treino do classificador ditam o conhecimento da gradação de notas distribuídas por ele. Portanto, o classificador recebe as características de cada resposta e a sua respectiva avaliação e as compara com as amostras de teste, com notas não conhecidas. Portanto, o modelo de classificação, tomado aqui como avaliador, produz as notas complementares para o conjunto de dados de teste.

Por fim, a elaboração de \textit{feedbacks} e relatórios é fundamental para o suporte ao professor. Em sala de aula, os \textit{feedbacks} são um material que detalha a avaliação para professores e alunos e descrevem o método avaliativo de forma a sanar qualquer dúvida e evidenciar qualquer problema no aprendizado. Por outro lado, na perspectiva da interação do professor com o sistema, os \textit{feedbacks} caracterizam a decisão, descrevem o modelo textual e a equivalência entre respostas. Portanto, em todos os ciclos do sistema esperamos reduzir o esforço de correção do tutor, apresentar resultados de alto nível com o modelo avaliativo e gerar materiais explicativos e completementares de qualidade.

\section{Objetivos} \label{cap1-objetivos}

O objetivo deste trabalho, portanto, é ajustar o modelo de correção criado pela máquina aos padrões estabelecidos pelo professor através da sua avaliação. Para isso, os modelos avaliativos devem compreender o método aplicado pelo professor, categorizando as respostas em classes, níveis ou intervalos contínuos de nota. Segundo a consistência de cada grupo, buscamos reduzir o esforço de correção do professor com a avaliação das respostas que apresentem apenas as principais caracteristicas textuais. Através de padrões bem definidos, esperamos reproduzir o critério avaliativo da questão justificando a classe atribuída através do seu respectivo sumário. Tal sumário, então, são os padrões de cada classe de nota partindo do agrupamento \textit{a priori} das questões. É através desse sumário por nota que recuperamos um possível critério de correção. Desta forma, através do \textit{p}Nota, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor para concentrar-se na verificação de aprendizagem do aluno.

Portanto, temos como âmbito principal a criação de modelos para aproximar o critério avaliativo aplicado ao aluno da definição de padrões de correção e a criação de \textit{feedbacks}. Para isso, estudamos os padrões avaliativos do professor e os métodos de representação do conhecimento encontrado em base de dados de questões discursivas curtas. Para atingir o objetivo geral descrevemos os seguintes objetivos específicos:

\begin{itemize}
\item Organizar os \textit{datasets} públicos da literatura para estabelecer uma comparação com resultados obtidos em estudos correlatos \cite{burrows2015};
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma gramatical, morfológica, semântica, sintática, estatística ou espacial \cite{galhardi2018a, kumar2019, sahu2020};
\item Interpretar minuciosamente as respostas e o alinhamento do conteúdo, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{jordan2012, saha2018, ding2020};
\item Elaborar e ajustar a avaliação de forma eficiente, assimilando o critério estabelecido pelo professor \cite{zesch2015, condor2020, pado2021};
\item Criar modelos avaliativos robustos, associando as categorias de nota aos padrões textuais \cite{butcher2010, heilman2015, burrows2015};
\item Identificar estruturas textuais para cada categoria de nota, removendo \textit{outliers} e controlando da consistência da classificação \cite{ding2020, filighera2020};
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{higgins2014, funayama2020, pado2021};
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{marvaniya2018, mizumoto2019, suzen2020}.
\end{itemize}

\section{Estrutura do Trabalho}

A seguir são apresentados os conteúdos dessa tese. A proposta é discutida em detalhes através de 5 capítulos. Para além da Introdução, o trabalho é composto dos seguintes capítulos:

\begin{itemize}
\item \textbf{Capítulo \ref{cap-literatura} - Revisão de Literatura:} Apresenta uma breve revisão da literatura sobre métodos de análise e avaliação de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-metodo} - Método:} Define a estrutura do sistema \textit{p}Nota e as formas utilizadas para efetuar de maneira abrangente a análise de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-experimentos} - Experimentos e Resultados:} Descreve por meio de oito \textit{datasets} as diferentes formas de apoio avaliativo, modelagem da relação termo-nota e a formação de \textit{feedbacks} utilizados pelo sistema.

\item \textbf{Capítulo \ref{cap-conclusao} - Conclusão:} Discute as contribuições deste trabalho, conclusões extraídas dos resultados obtidos e as perspectivas de trabalhos futuros.

\end{itemize}