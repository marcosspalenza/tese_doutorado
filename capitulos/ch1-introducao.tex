% ==============================================================================
% TCC - Nome do Aluno
% Capítulo 1 - Introdução
% ==============================================================================
\chapter{Introdução}
\label{cap-intro}

\begin{comment}
O documento é organizado em capítulos (\texttt{\textbackslash chapter\{\}}), seções (\texttt{\textbackslash section\{\}}), subseções (\texttt{\textbackslash subsection\{\}}), sub-subseções (\texttt{\textbackslash subsubsection\{\}}) e assim por diante. Atenção, porém, a não criar estruturas muito profundas (sub-sub-sub-...) pois o documento não fica bem estruturado.
\end{comment}

As avaliações de aprendizado são fundamentais para todos os níveis de ensino. É por meio do método avaliativo que o professor observa o desempenho da turma e seu progresso nos conteúdos. Com aplicações frequentes, as atividades permitem ao professor interagir com os alunos e com os materiais pedagógicos para reformulação e aperfeiçoamento da sua metodologia. Desse modo, é com o acompanhamento da disciplina e o apoio ao educando que as atividades permitem a reformulação e controle do processo de ensino-aprendizagem \cite{barreira2006}. Por meio das atividades podemos identificar o domínio dos estudantes sobre o contexto e sua capacidade de realizar inferências sobre o assunto. O papel da avaliação, portanto, é diagnosticar, apreciar e verificar a proficiência dos alunos para que o professor atue no processo de formação de modo a consolidar o aprendizado \cite{oliveira2005}.


É através do modelo de ensino-aprendizagem, que o professor observa problemas e age para contorná-los. Essa identificação de problemas e sua rápida solução torna a estrutura curricular personalizada, alinhando a turma de acordo com os objetivos da disciplina. É através das atividades, portanto, que é possível mensurar o conhecimento individual dos alunos. Um modo de aperfeiçoar a aplicação das atividades em quantidade e qualidade é dada através da mediação tecnológica. A mediação tecnológica na criação, avaliação, recomendação e visualização em dados educacionais apoia o professor na melhoria e no acompanhamento do currículo do aluno \cite{paiva2012}. É com as ferramentas de apoio, então, que o tutor pode verificar a aptidão dos estudantes, de forma individual ou coletiva, para melhorar a adaptação e a experiência com a disciplina.

Na literatura da Avaliação Assistida por Computadores (\textit{Computer Assisted Assessment} - CAA em inglês), existe uma extensa pesquisa por métodos para avaliação de questões discursivas. Sabendo que existe um critério formulado pelo professor para correção das respostas discursivas, propomos uma abordagem de reconhecimento dos padrões de textuais. Assim, neste trabalho descrevemos um modelo semi-supervisionado para reconhecimento do método avaliativo, extração de padrões textuais, classificação da base de dados e produção de \textit{feedbacks}. Considerando a liberdade textual característica das respostas discursivas, verificamos a similaridade entre respostas e os grupos de termos referenciais para atribuir notas de forma equivalente ao avaliador humano. Com os modelos de SAG, esperamos também demonstrar o método avaliativo com a criação de \textit{feedbacks}, como o quadro de \textit{rubrics} \cite{arter2006} e, consequentemente, melhorar os métodos de avaliação automática \cite{spalenza2016SBIE}.

\section{Problema} 
\label{sec-problema}

Dentro da literatura da avaliação de respostas discursivas curtas, em inglês \textit{Short Answer Grader (SAG)}, encontramos determinados problemas listados pelos autores para criação de melhores modelos avaliativos. Apesar de ser um estudo já realizado há décadas, em SAG encontramos desafios observados durante a aplicação da avaliação automática como demandas importantes e pouco estudadas até o momento. Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto bruto. A partir disso, a busca por equivalência entre a resposta esperada e o texto dos estudantes falhou por inúmeras vezes na padronização dos documentos e na identificação de sinônimos \cite{leffa2003}. O estudo dessa pesquisa fomentou inúmeras discussões em torno da identificação do conhecimento obtido pelas respostas escritas pelo aluno. A robustez dessa análise é parte fundamental de boa parte dos algoritmos atuais em SAG. Portanto,  para a recuperação da relação entre o conteúdo e a nota atribuída são aplicadas diversas técnicas entre Aprendizado de Máquina, Estatística, Processamento de Linguagem Natural, Reconhecimento de Padrões, dentre outras.

% (Machine Learning - ML)
% (Natural Language Processing - NLP)
% (Pattern Recognition - PR)
% (Educational Data Mining - EDM)

Em uma revisão da literatura sobre os sistemas SAG \cite{burrows2015}, os autores reúnem 37 trabalhos realizados na área. Durante essa revisão, o autor destaca o problema da  profundidade do aprendizado, tradução literal de ``\textit{depth of learning}'', separando as atividades em dois grupos: de reconhecimento e de recuperação. Tais modelos têm diferentes intúitos na aquisição de informação do aluno o que gera diferentes modos de processamento. No Brasil, conhecemos essas por questões abertas e fechadas, nomenclaturas também citadas pelos autores. Essa divisão estabelece a diferença entre as atividades que exploram apenas a necessidade de identificação e organização de conteúdo e as que dependem de construção de ideias visando respostas próprias e originais. Portanto, por definição, a chave para separar atividades que necessitem de maior ou menor conhecimento factual, ou questões abertas e fechadas, é a liberdade que o aluno possui para criação do seu conjunto de resposta.

Um problema com esse viés é reagir às questões discursivas factuais e opinativas da forma adequada \cite{bailey2008}. É esperado que o sistema lide com a liberdade de escrita do aluno recuperando o conteúdo. A forma aqui proposta para contornar esse problema de identificação do critério avaliativo parte de interações com o especialista. Essas interações são requisições de correção para buscar avaliações específicas de padrões textuais das respostas. Esse processo seleciona documentos que indiquem certo grau de distinção por grupo, resultante de uma clusterização inicial \cite{oliveira2014}. Coletamos assim a classificação dada para os itens elencados como relevantes pelo sistema em cada \textit{cluster} para continuidade do processo avaliativo.

Desta forma, a modelagem de classificadores de forma semi-supervisionada permite que encontremos grupos de respostas através da clusterização. A partir daí devemos encontrar qual é o critério avaliativo do professor, sem requisitar exemplos e chaves de resposta, dado até o momento como necessário \cite{butcher2010, mohler2011, ramachandran2015a}. Basicamente, a análise de distribuição de características e a seleção de respostas visa remontar o critério do professor, otimizando o processo de correção automática.

O problema passa da necessidade de avaliação para o aumento do número de padrões à serem avaliados pelo professor para relacionar conteúdo com classificação. Um dos principais sistemas, \textit{FreeText Author}, apresenta problemas importantes para um efetivo processo avaliativo automático \cite{butcher2010}. Os autores, em uma análise detalhada deste sistema, listaram seis problemas. O primeiro que podemos destacar é a omissão dos padrões de avaliação. O segundo, a identificação de associações entre palavras e o método avaliativo de forma inconsistente. O terceiro problema, conforme os autores, é a necessidade de identificação estrutural da sentença. A quarta dificuldade listada é o tratamento de classificações incorretas por parte do especialista. O quinto problema é o conflito de um padrão correto de resposta com uma avaliação dada como incorreta. Por fim, seguindo a linha do quarto e quinto problema citado, um sexto problema é dado pela confiabilidade do sistema como avaliador em relação a interpretação textuais inconsistentes.


É importante descrever ainda a diferença entre o conjunto de informações selecionadas para a classificação correta das respostas e a interpretação avaliativa \cite{ramachandran2015a}. A separação do cunho interpretativo do interlocutor deve ser estritamente analisada conforme o modelo avaliativo. Se os padrões de nota e de resposta estiverem em conformidade com a avaliação do especialista, a redução de dimensionalidade dada pela otimização deve indicar uma boa interpretação da relação termo-classe. Assim, encaramos a avaliação como um processo constante e passível de revisões, para que o ajuste do sistema torne o modelo extraído cada vez mais próximos das expectativas do professor. 

Por fim, podemos ainda citar dificuldade em encontrar os \textit{datasets} utilizados por trabalhos da literatura \cite{burrows2015}. É muito comum encontrar trabalhos no qual os autores coletaram dados na própria universidade e não as tornam públicas. Além disso, em SAG uma base de dados adequada deve caracterizar o processo avaliativo do professor e constar com relevantes resultados na literatura. Entretanto, o intúito deste trabalho é propor algumas soluções para tais problemas. Assim, buscamos avanços desde a descrição dos conjuntos de dados disponíveis até a apresentação de uma possível solução para a associação entre a atribuição de notas e o aspecto textual da resposta.

\begin{comment}
Por conta disso, a ferramenta proposta por neste trabalho faz análises diretas nas respostas enviadas pelos alunos e realiza pré-processamentos para tornar grupos de termos e documentos equivalentes. Alguns módulos foram adicionais para compreender melhor a estrutura frasal e compreender a escrita de cada resposta em níveis gramaticais, sintáticos e morfológicos. A avaliação dada apenas com base na sintaxe, ortografia ou organização não são suficientes para as questões discursivas curtas \cite{ramachandran2015a}.

Após os módulos linguísticos, os demais problemas serão cautelosamente trabalhados através de metodos de recuperação da informação. Assim, o 4º problema esclarece a dificuldade em separar possíveis \textit{outliers} das informações relevantes que foram apresentadas em uma única ou poucas ocasiões no banco de dados. Nosso método de contornar essa adversidade é dada pelo envio de padrões distintos para a avaliação humana, em busca de referências ao conteúdo. Desta forma, a ferramenta trabalha cada nota como um rótulo dado pelo especialista, criando um modelo mais detalhista do que a análise de uma resposta candidata elaborada pelo professor.

No 5º problema, sobre a localização de padrões de avaliação incorretamente classificados pelo especialista, há um impacto grave na adaptabilidade da máquina como avaliador. Em torno disso, interpretamos conjuntos de  avaliação para ajustar seu modelo de classificação, extraindo cada alteração como conhecimento. Assim, o sistema poderá identificar qual informação difere na resposta para o modelo avaliativo construido. Tal processo torna-o mais específico ou genérico segundo a variação da nota atribuida ao documento. O mesmo esperamos que ocorra no último problema listado pelos autores, a confiabilidade do sistema na modelagem do critério de avaliação. Com o ajuste da avaliação pelo professor durante etapas de revisão, esperamos que o sistema modifique seu modelo, refinando-o.

Em relação a issoNeste estudo esperamos realizar comparações em, ao menos, três \textit{datasets} que temos acesso e são conhecidos da literatura e dois \textit{datasets} locais. Nesses \textit{datasets} que temos disponíveis, apresentados em detalhes na Seção \ref{cap5}, encontramos uma variação no padrão de notas (contínuas ou discretas), na avaliação de um ou mais especialistas e na existência ou não de respostas candidatas. Tal variabilidade permite que diferentes testes sejam realizados para investigar o modelo avaliativo do professor, seja ele dado pela nota atribuida ou pela resposta candidata.

\end{comment}

\section{Proposta}
\label{cap1-proposta}

Neste trabalho apresentamos um método de avaliação de respostas discursivas curtas através de modelos avaliativos complexos. Para seu desenvolvimento, buscamos identificar problemas mais comuns descritos na literatura como deficiências dos sistemas \textit{Short-Answer Graders} (SAG) para apresentar uma proposta de solução. A ideia é compor um sistema para reconhecer a relação entre as respostas e as notas atribuídas de acordo com o método avaliativo do professor. Com isso, esperamos atender a demandas atuais dos trabalhos em SAG por meio de técnicas de \textit{Educational Data Mining} (EDM), \textit{Machine Learning} (ML) e \textit{Natural Language Processing} (NLP). Para a criação dos modelos selecinamos diferentes bases de dados de respostas discursivas curtas disponíveis em \textit{inglês} e \textit{português}. Dentre os \textit{datasets} observamos 3 tipos de avaliações: notas discretas, notas graduais e notas contínuas. Portanto, neste trabalho, estudamos estruturas para identificação das principais respostas do conjunto, reconhecimento do método avaliativo do professor (especialista) e elaboração \textit{feedbacks}. 

Para identificação das principais respostas apresentamos um modelo de aprendizado semi-supervisionado. No aprendizado semi-supervisionado o especialista ativamente passa o conhecimento para o algoritmo de classificação. O algoritmo, por sua vez, utiliza o as informações passadas para criar um modelo que imite o especialista na tarefa. Neste caso, o professor ensina ao sistema seu método avaliativo e, através da atribuição de notas, é formado um modelo que tenta replicar o método para as demais respostas da atividades. Cada uma das respostas enviadas para atividade é considerada uma amostra para o sistema. Dentre todas as amostras, é fundamental que o sistema aprenda cada uma das características das respostas, selecionando as principais por representatividade. Para essa seleção o sistema utiliza de técnicas de otimização e clusterização. As respostas selecionadas são denominadas de treinamento, pois serão utilizadas para produção dos modelos, enquanto as demais são o conjunto de teste.

No reconhecimento do método avaliativo do professor, modelos são criados para classificação das respostas discursivas. A categorização deve se aproximar ao máximo da tarefa realizada pelo professor, analisando detalhes parecidos na resposta. Portanto, o modelo avaliativo do sistema objetiva atender as expectativas do professor. Quanto menor a diferença entre a nota dada pelo sistema e a nota atribuída pelo professor, melhor o modelo criado. Consequentemente, os melhores modelos representam melhor a diversidade de notas e respostas com tendência menor de erros. Na gradação das notas, quanto maior a discrepância entre as notas mais críticos são os erros. Sabendo que, entre avaliadores humanos também existe esse erro. Os dados selecionados para treino do classificador ditam o conhecimento da gradação de notas distribuídas por ele. Portanto, o classificador recebe as características de cada resposta e a sua respectiva avaliação e as compara com as amostras de teste, com notas não conhecidas. Portanto, o modelo de classificação, tomado aqui como avaliador, produz as notas complementares para o conjunto de dados de teste.

Por fim, a elaboração de \textit{feedbacks} e relatórios é fundamental para o suporte ao professor. Em sala de aula, os \textit{feedbacks} são um material que detalha a avaliação para professores e alunos e descrevem o método avaliativo de forma a sanar qualquer dúvida e evidenciar qualquer problema no aprendizado. Por outro lado, na perspectiva da interação do professor com o sistema, os \textit{feedbacks} caracterizam a decisão, descrevem o modelo textual e a equivalência entre respostas. Portanto, em todos os ciclos do sistema esperamos reduzir o esforço de correção do tutor, apresentar resultados de alto nível com o modelo avaliativo e gerar materiais explicativos e completementares de qualidade.

\section{Objetivos} \label{cap1-objetivos}

O objetivo deste trabalho, portanto, é ajustar o modelo de correção criado pela máquina aos padrões estabelecidos pelo professor através da sua avaliação. Para isso, os modelos avaliativos devem compreender o método aplicado pelo professor, categorizando as respostas em classes, níveis ou intervalos contínuos de nota. Segundo a consistência de cada grupo, buscamos reduzir o esforço de correção do professor com a avaliação das respostas que apresentem apenas as principais caracteristicas textuais. Através de padrões bem definidos, esperamos reproduzir o critério avaliativo da questão justificando a classe atribuída através do seu respectivo sumário. Tal sumário, então, são os padrões de cada classe de nota partindo do agrupamento \textit{a priori} das questões. É através desse sumário por nota que recuperamos um possível critério de correção. Desta forma, através do \textit{p}Nota, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor para concentrar-se na verificação de aprendizagem do aluno.

Portanto, temos como âmbito principal a criação de modelos para aproximar o critério avaliativo aplicado ao aluno da definição de padrões de correção e a criação de \textit{feedbacks}. Para isso, estudamos os padrões avaliativos do professor e os métodos de representação do conhecimento em base de dados de questões discursivas curtas. Para atingir o objetivo geral descrevemos os seguintes objetivos específicos:

\begin{itemize}
\item Organizar \textit{datasets} públicos e locais para comparação direta com resultados obtidos em estudos correlatos \cite{burrows2015}.
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma léxica, morfológica, semântica, sintática, estatística ou espacial \cite{burrows2015, butcher2010}.
\item Unificar padrões de respostas dadas por professores e alunos, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{butcher2010}.
\item Criar modelos avaliativos através do reconhecimento de padrões variáveis em categorias em dados discretos e contínuos \cite{burrows2015}.
\item Elaborar e ajustar modelos de acordo com a eficiência do sistema na recuperação da resposta atribuída pelo professor e seu modelo avaliativo \cite{burrows2015}.
\item Identificar a relação da avaliação com o comportamento textual da classe para remoção de \textit{outliers} e manter a consistência da classificação \cite{butcher2010}.
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{butcher2010}.
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{oliveira2010}.
\end{itemize}

\section{Estrutura do Trabalho}

A seguir são apresentados os conteúdos dessa tese. A proposta é discutida em detalhes através de 5 capítulos. Para além da Introdução, o trabalho é composto dos seguintes capítulos:

\begin{itemize}
\item \textbf{Capítulo \ref{cap-literatura} - Revisão de Literatura:} Apresenta uma breve revisão da literatura sobre métodos de análise e avaliação de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-metodo} - Método:} Define a estrutura do sistema \textit{p}Nota e as formas utilizadas para efetuar de maneira abrangente a análise de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-experimentos} - Experimentos e Resultados:} Descreve por meio de oito \textit{datasets} as diferentes formas de apoio avaliativo, modelagem da relação termo-nota e a formação de \textit{feedbacks} utilizados pelo sistema.

\item \textbf{Capítulo \ref{cap-conclusao} - Conclusão:} Discute as contribuições deste trabalho, conclusões extraídas dos resultados obtidos e as perspectivas de trabalhos futuros.

\end{itemize}