% ==============================================================================
% TCC - Nome do Aluno
% Capítulo 1 - Introdução
% ==============================================================================
\chapter{Introdução}
\label{cap1-intro}

A avaliação é uma etapa fundamental para o ensino, inclusive para garantir a eficiência dos processos de ensino-aprendizagem. Através do método avaliativo que o professor mensura a assimilação do conteúdo ministrado. Portanto, é por meio das avaliações que o professor observa o desempenho da turma e seu progresso nos conteúdos. Nesse aspecto, é fundamental que o professor verifique com frequência o aprendizado dos estudantes no decorrer da disciplina. Assim, essa aplicação permite ao professor interagir com os alunos junto com os materiais pedagógicos para reformulação e aperfeiçoamento da dinâmica de ensino. Deste modo, é com o acompanhamento da disciplina e o apoio ao educando que as atividades estabelecem meios de reformular e controlar o processo de ensino-aprendizagem \cite{barreira2006}.

Através das atividades, somada ao acompanhamento em sala, avaliamos a proficiência dos estudantes sobre determinado domínio. A proficiência envolve avaliar o raciocínio segundo a capacidade de resolver problemas, tomar decisões e realizar inferências sobre o assunto \cite{casiraghi2017}. O papel da avaliação, portanto, é diagnosticar, apreciar e verificar o aprendizado dos alunos para que o professor atue no processo de formação de modo a consolidar seu método de ensino \cite{oliveira2005}. Deste modo, além do desenvolvimento e da sequência de métodos avaliativos, são imprescindíveis a verificação dos resultados e a correção de problemas nos métodos de ensino-aprendizagem.

O método avaliativo é o que torna possível o acompanamento e a solução dos problemas com o aprendizado dos alunos. Essa identificação de problemas e as ações para contorná-los tornam a estrutura curricular personalizada, alinhando a turma de acordo com os objetivos da disciplina \cite{biggs1998}. Portanto, é através das atividades que criamos o modelo para mensurar o conhecimento individual dos alunos. Para isso, a mediação tecnológica consolidou-se para aplicação das atividades em quantidade e qualidade. Deste modo, os Ambientes Virtuais de Aprendizagem (AVA) \cite{maquine2020} se tornaram modelos virtuais para suporte das aulas para turmas presenciais e a distância \cite{raes2020}. Com a mediação tecnológica, apoiamos o professor na criação, avaliação, recomendação e visualização de dados educacionais impactando diretamente no acompanhamento do currículo do aluno \cite{paiva2012}. Deste modo, é com as ferramentas de apoio que o tutor verifica a aptidão dos estudantes, de forma individual ou coletiva, para melhorar a adaptação e a experiência da disciplina.

Nesse ponto, o acompanhamento, a formulação, a aplicação e os resultados dos métodos avaliativos em meio computacional são estudados pela área de \textit{Computer-Assisted Asssessment} (CAA) \cite{bogarin2018}, ou em tradução literal Avaliação Assistida por Computadores. Na literatura de CAA, existe uma extensa pesquisa por métodos avaliativos e sua aplicação de forma digital \cite{perez-marin2009}. Em especial, destacamos as questões discursivas curtas, fundamentais para o desenvolvimento da escrita para aplicação em ampla escala neste formato. A avaliação de questões discursivas é dispendiosa, demandando análises da relação de cada resposta com seu alinhamento com o tema. Portanto, o estudo de formas computacionais para suporte aos métodos de avaliação de respostas discursivas, garantem maior capacidade de aplicação e correção para mensurar o aprendizado.

As questões discursivas incluem vários modelos avaliativos, das questões de preenchimento até longas redações. Neste trabalho, entretanto, buscamos dar suporte ao professor na avaliação de respostas discursivas curtas. Ainda assim, com \textit{datasets} de diferentes características de resposta e avaliação, definimos como respostas curtas conjuntos textuais de até 3 sentenças, compostos por até 100 palavras. Para caracterizar as respostas discursivas curtas apresentamos na Tabela \ref{tab-pgq2-exemplo} a atividade de exemplo \textit{Powergrading-A2}.

\begin{table}
\centering
\caption{Exemplo de respostas curtas com amostras da questão Q2 do \textit{dataset Powergrading}.}
\label{tab-pgq2-exemplo}
\begin{tabular}{ r | r}
\hline
\multicolumn{2}{l}{\textbf{Powergrading}} \\ \hline
\multicolumn{2}{c}{\textbf{Q2}} \\ \hline 
\multicolumn{2}{l}{\textit{What is one right or freedom from the First Amendment of the U.S. Constitution?}} \\ \hline
 \# & Resposta \\ \hline
fbccf723b6ca & freedom of speech  \\
10814c63d220 & freedom of speech \\
0704a8d6f8d9 & to bear arm \\
256b545c9f10 & free excess of religion \\
a83446496fcb & freedom of speech \\
83bbefc5bbae & freedom of speech. \\
f28ffbdde6b9 & to bear arms \\
bc65e0296be8 & freedom of speech. \\
3e1216d9295e & freedom of speech \\
830444330cd9 & life \\
815667698f42 & right to pursue happiness. \\
\\
\\
\hline
\hline
\end{tabular}
\end{table}

A Tabela \ref{tab-pgq2-exemplo} apresenta o enunciado da questão e uma pequena amostra dos identificadores e respostas enviadas pelos estudantes. Vamos utilizar essa questão Q2 do \textit{dataset Powergrading} como modelo de questão discursiva curta. Nesta questão temos respostas sucintas para um enunciado que direciona para um ou poucos caminhos de resposta que podem ser desenvolvidos pelos estudantes. Nas respostas selecionadas vemos diferentes direções seguidas pelos estudantes. Porém, segundo a constituição americana:

\begin{quote}
\textit{Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the government for a redress of grievances.}
\end{quote}

Deste modo, todos que responderam algo descrito na \textit{Primeira Emenda} estão corretos. Entretanto, como o próprio exemplo indica, os \textit{datasets} são característicos pela liberdade de escrita e diversidade de conteúdos. A liberdade de escrita é caracteristica em questões abertas, ou seja, aonde há produção textual por parte do estudante. Assim, a liberdade de escrita é expressa pelas diferentes formas que os estudantes se referem a um ou mais modelos de resposta. Devido a essa liberdade, devemos formar representações do conteúdo que demonstram a perspectiva de cada um dos participantes do método avaliativo.

Na aplicação de questões discursivas é comum que exista uma expectativa de convergência entre respostas, de forma a não criar respostas únicas e pessoais. Designamos então como \textit{modelo de respostas}, a tendência de determinados conjuntos de resposta de estudantes apresentarem entre si certo índice de similaridade. Por outro lado, em uma perspectiva avaliativa do professor, existe o alinhamento entre conteúdo ministrado em sala e conteúdo esperado nas respostas. Encontramos este alinhamento nas \textit{respostas candidatas}, ou seja, respostas produzidas pelo professor para caracterizar a expectativa de resposta de acordo com o enunciado da atividade. Por fim, na perspectiva do sistema, existem os padrões textuais. Com a análise do texto através de métodos de reconhecimento de padrões, identificamos características que definem grupos de conteúdo em meio a diversidade textual. Denominamos tais grupos como \textit{padrões de resposta}, pois caracterizam grupos de resposta ao sistema para compreensão do conteúdo e do tema abordado. 

Cada uma das perspectivas sobre o conjunto de respostas é importante para designar as formas com a qual cada um no processo avaliativo observa a diversidade textual. Portanto, na visão dos alunos, temos a convergência das respostas na formação de modelos. Na análise do professor, os modelos têm viés avaliativo, e esse viés é representado através de respostas candidatas ou expectativas de resposta. As respostas candidatas são instâncias textuais, ou seja, são respostas de referência tal qual as produzidas pelos estudantes. Por outro lado, as expectativas de resposta são segmentos do conteúdos que demonstram traços da avaliação, caracterizando o processo avaliativo. E, por fim, na ótica do sistema, a equivalência entre as estruturas textuais indicam padrões, formados por grupos de resposta com as mesmas características.

Sabendo da complexidade do processo avaliativo, caracterizado pela análise de todo conteúdo, atribuição de notas e revisão de resultados, enfatizamos diversidade textual. A diversidade textual inclui as diferentes formas de linguagem adotadas. Isso inclui todas as possibilidades de atingir a expectativa de resposta do professor de acordo com o método avaliativo. Assim como o professor, a automação do processo de análise textual inclui compreender as tendências de resposta de acordo com o conteúdo abordado. Deste modo, as características linguísticas do conjunto textual deve ser analisadas tal qual o realizado por um especialista, nesse caso o professor. Com essa perspectiva, o objetivo geral dos sistemas de CAA é reduzir o esforço avaliativo e a análise de toda diversidade textual. Para isso, os sistemas devem criar modelos linguísticos robustos, de forma a ter alto nível de compreensão linguística e interpretação textual. Essa robustez é indicada dado o potencial de identificar respostas distintas com mesmo viés de resposta, aproximando-se da linguagem dos professores e alunos.

Por isso, o reconhecimento das estruturas que formam a linguagem escrita são fundamentais para a descoberta de modelos, padrões e características relevantes nas respostas. Cada resposta, como um documento textual, é composta por uma série de características. Cada característica é extraída de acordo com a construção da estrutura textual, seja ela no aspecto gramatical, morfológico, semântico, sintático, estatístico ou sequencial. Portanto, a identificação das características mais relevantes nas respostas que formam os padrões para o sistema. A Tabela \ref{tab-features} apresenta os valores médios da composição de cada \textit{dataset} segundo suas características textuais.

% TABELA CARACTERISTICAS
\begin{table}
\centering
\caption{Média de observados nas respostas }
\label{tab-features}
\begin{tabular}{|r | r r r|} \hline
\textit{Dataset} & Características & Palavras & Caracteres \\
\hline
UNT & 140 & 20 & 107 \\
ASAP & 2932 & 43 & 236 \\
Beetle & 98 & 10 & 50 \\
Open University & 418 & 10 & 55 \\
Findes & 123 & 8 & 40 \\
Powergrading & 178 & 4 & 20 \\
PTASAG & 906 & 13 & 72 \\
SEB & 110 & 13 & 64 \\
VestUFES & 1391 & 92 & 536 \\
\hline \hline
\end{tabular}
\end{table}

Como a Tabela \ref{tab-features} destaca, mesmo sobre um tipo específico de questão, temos variações importantes no modelo de resposta. Apesar de todos os conjuntos se enquadrarem nas especificações de respostas com menos de 100 palavras ou 3 sentenças, são evidentes as diferenças entre \textit{datasets}. Enquanto majoritariamente temos conjuntos com respostas bem concisas (menores que 20 palavras), temos VestUFES e ASAP mais descritivos e, possívelmente, com enunciados mais abstratos. Diante do escopo delimitado para as respostas, sobressaem alguns desafios na compreensão computacional da linguagem e dos métodos avaliativos. Deste modo, é fundamental a produção de modelos avaliativos computacionais que demonstrem fluência no método adotado. Portanto, modelos avaliativos designam sistemas que aplicam o método de forma similar ao professor, realizando a inferência avaliativa.

Por conta dos vários desafios nas técnicas de CAA, porpomos um modelo de \textit{Active Learning} com análise das estruturas que compõe o texto em uma aplicação de reconhecimento de padrões. Em \textit{Active Learning} utilizamos de técnicas em \textit{Unsupervised Learning}, para seleção de amostras pela distribuição espacial, e \textit{Supervised Learning}, para construção de avaliadores alinhados ao padrão de notas identificado. Assim, o sistema chamado \textit{p}Nota, apresenta a combinação de técnicas de pré-processamento, clusterização, amostragem, classificação e produção de \textit{feedbacks} para criar um modelo consistente em relação a expectativa do professor. Dentro das estruturas textuais, investigamos a construção de cada uma das sentenças sob diferentes perspectivas, avaliando aspectos gramaticais, morfológicos, semânticos, sintáticos, estatísticos e sequenciais que formam o conjunto de respostas. Sendo a atribuição de notas de interesse do professor, as respostas são comparadas diante de sua similaridade em diferentes modelos de classificação ou regressão. Deste modo, com o modelo proposto para avaliação de respostas discursivas curtas (ou \textit{Short Answer Graders} (SAG), esperamos identificar padrões de resposta, reproduzir o método avaliativo e criar \textit{feedbacks} descritivos para todos os participantes da disciplina \cite{arter2006, spalenza2016a}.

\section{Problema} 
\label{cap1-problema}

Dentro da literatura dos sistemas SAG, encontramos determinados problemas que foram listados por autores durante os anos de evolução da pesquisa. Os problemas são amplos, onde se busca aprimorar gradativamente os modelos avaliativos para conseguir resultados cada vez mais adequados aos do professor \cite{pado2021}. Assim, buscamos para além da redução do esforço de correção, a ampliação da análise e a proximidade entre modelos avaliativos. A expectativa é a redução de erros nos modelos avaliativos, com o modelo do avaliador automático aproximando-se do modelo do professor, enquanto especialista no tema. Nesse aspecto, mesmo que seja um trabalho realizado há decadas \cite{burrows2015}, a literatura dos modelos SAG descreve demandas importantes e pouco estudadas até o momento.

Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto bruto \cite{perez-marin2009}. A partir disso, a busca por equivalência entre a resposta esperada e o texto dos estudantes falhou por inúmeras vezes na padronização dos documentos e na identificação de sinônimos \cite{leffa2003}. O estudo dessa pesquisa fomentou inúmeras discussões em torno da identificação do conhecimento obtido pelas respostas escritas pelo aluno. Por conta disso, a robustez dessa análise é parte fundamental de boa parte dos algoritmos atuais em SAG \cite{filighera2020}.

Na principal revisão da literatura sobre os sistemas SAG \cite{burrows2015}, os autores reúnem 37 trabalhos realizados na área.
% TODO

 Durante esse estudo, o autor destaca o problema da  profundidade do aprendizado, em tradução literal para ``\textit{depth of learning}'', separando as atividades em dois grupos: de reconhecimento e de recuperação. No Brasil, conhecemos discriminamos os dois tipos de questão como abertas e fechadas \cite{gunther2012}. Então, é característica dos modelos SAG a produção de modelos complexos de correção de questões de recuperação, interpretando computacionalmente o conteúdo de respostas curtas em textos de escrita livre.

Um problema diretamente associado ao modelo de interpretação textual, entretanto, é a busca de convergência entre as respostas. É uma dificuldade a extração do viés de resposta em questões discursivas factuais com múltiplos contextos. Além disso, existe ainda maior complexidade para lidar com questões que resultam em respostas opinativas, individuais ou subjetivas \cite{bailey2008}. Apesar do conteúdo, é esperado do sistema que, independente do conteúdo recebido do professor, lide com a liberdade de escrita do estudante e analize a convergência entre respostas na tentativa de recuperar padrões compatíveis \cite{saha2018}. 

Em geral, para além do reconhecimento de padrões de resposta, ainda existe o alinhamento entre o conteúdo das respostas e o critério avaliativo. Esse fator se destaca pela referência utilizada na criação do modelo avaliativo \cite{krithika2015}. O professor, no papel de especialista, deve ser seguido segundo seu padrão avaliativo na tentando imitá-lo \cite{jordan2012, funayama2020}. Para ilustrar esse aspecto podemos usar como exemplo a avaliação de plágios de forma negativa. Como é de interesse dos sistemas SAG seguir o modelo avaliativo do professor, mesmo que a essência do conteúdo seja coincidente com respostas próximas, o padrão específico reconhecido negativamente deve receber avaliação equivalente por conta do plágio segundo o método avaliativo do professor. Assim, apesar da escolha de palavras alinhadas com um determinado modelo de resposta, é essencial que o sistema forme vínculos entre padrões de avaliação e de respostas para criação de modelos avaliativos robustos \cite{higgins2014}. Nesse aspecto destacamos que é fundamental para além de um sistema tradicional de reconhecimento de padrões a extração do critério avaliativo do professor.

Sabendo disso, o critério avaliativo deve atrelar componentes textuais ao método avaliativo. A aquisição desse modelo deve ser feita através da identificação da forma que o professor avalia uma série de respostas. Porém, uma série de trabalhos utiliza descritores do padrão avaliativo para representar a forma que o professor interpreta modelos de resposta dentre expressões regulares e regras até o quadro de \textit{rubrics} \cite{butcher2010, mohler2011, ramachandran2015a}. Porém, isso contrapõe a proposta de reduzir o esforço avaliativo do professor, se considerarmos a necessidade de produção de qualquer conteúdo extra sobre a avaliação \cite{zesch2015, horbach2018}. A partir daí para remontar o critério avaliativo do professor, deve priorizar o uso de padrões de avaliação sem requisitar descritores ou chaves de resposta.

Dentro desse aspecto, durante a análise da compatibilidade entre os modelos do sistema \textit{FreeText Author} e do professor \cite{butcher2010}, os autores elencaram seis problemas. O primeiro é a omissão dos padrões de avaliação. O segundo é a identificação da associação entre palavras e a sua conexão com o modelo avaliativo. O terceiro é a necessidade de identificação estrutural da sentença. O quarto é o tratamento de classificações incorretas, em especial por parte do especialista. O quinto é o conflito entre padrões corretos e incorretos. E, por fim, o sexto problema listado pelos autores é diretamente relacionado aos demais, indicando o problema de confiabilidade do sistema como avaliador e a interpretação inconsistente do conteúdo textual.

Na perspectiva da omissão dos padrões avaliativos, detalhamos a diferença entre o sistema ter o conhecimento dos padrões textuais e a avaliação de padrões desconhecidos. Padrões desconhecidos podem ter \textit{outliers} que estritamente recebem um modelo próprio de avaliação \cite{filighera2020}. Entretanto, para além dos métodos aleatórios de amostragem, a avaliação de questões discursivas curtas \textit{a priori} indica um problema de classificação desbalanceada \cite{dzikovska2012}. Deste modo, destacamos a importância dos métodos de anotação direcionada a diversidade textual e uso de métodos de verificação da distribuição das amostras \cite{marvaniya2018}.

O segundo listado, em uma outra esfera avaliativa, estabelece a criação de modelos robustos entre termos e classes \cite{ramachandran2015a}. Portanto, torna-se característico segundo os autores que os modelos SAG devem incorporar detalhes sutis da avaliação \cite{horbach2018}. Portanto, a relação termo-classe deve ser dinâmica e, apesar da avaliação ser passível de revisões e ajustes a qualquer momento, sempre extrair o modelo que melhor atenda às expectativas do professor \cite{spalenza2016a}.

Na sequência, o terceiro problema listado é de aspecto estrutural, observando cada resposta segundo os detalhes de sua construção. Por consequência, além da análise detalhada do modelo textual, é fundamental uma extensa capacidade analítica do conteúdo \cite{saha2018}. Portanto, além do nível textual desejamos que a análise seja feita em vários níveis, incluindo verificação morfológica, semântica e sintática de cada resposta \cite{sakaguchi2015, riordan2019, sahu2020}. Deste modo, incluimos neste aspecto, além de formas de maximizar a aquisição de informações em texto, a análise estrutural para compreensão da escrita das respostas. Somado a isso, algumas abordagens vão além e ainda exploram a conexão semântica entre respostas, questões e domínios \cite{dzikovska2013, saha2019}.

O quarto problema inclui o tratamento de classificações incorretas. É extremamente relevante aos sistemas SAG a construção de justificativas com fundamentos em referências textuais \cite{funayama2020}. Assim, é recorrente a possibilidade de remontar as componentes que levam a correção de cada resposta, sejam regras de associação de respostas, padrões de expressões regulares ou a extração de características textuais \cite{chakraborty2017, kumar2019}. Para além da necessidade de justificativa, para cada nota atribuída, ainda ressaltamos a capacidade de identificar \textit{outliers} \cite{ding2020} e garantir que não se torne uma influência ao método avaliativo. Nessa linha, é importante que os modelos compreendam o conteúdo sem avaliações tendenciosas \cite{azad2020}, realizando uma análise ampla do conteúdo anotado.

De forma contínua ao quarto, o quinto problema compreende a identificação de incoerências nas avaliações. Entretanto, a incoerência é algo esperado desde que a divergência existe mesmo que entre dois humanos especialistas \cite{artstein2008, pado2021}. Mas é essencial minorar a diferença cada vez mais entre o modelo do especialista e o modelo de avaliação automática \cite{condor2020}. Nessa dinâmica, ressaltamos a importância em isolar comportamentos anômalos do método avaliativo para que não influencie no comportamento geral do modelo automático.

Por fim, a confiabilidade do sistema, tangenciando todos os demais citados, é tratada no último item. Superficialmente podemos associar este problema a divergência de notas entre avaliadores. Porém, em um aspecto amplo, a confiabilidade do sistema passa do reconhecimento do critério avaliativo à criação de justificativas de nota através de modelos descritivos de \textit{feedback} \cite{kumar2019}. O papel dos modelos de \textit{feedback} vai além de descrever o que o sistema observou na avaliação. Este declara a todos os participantes a relação entre as respostas, o reconhecimento do critério de avaliativo e cada anotação do professor \cite{marvaniya2018}. Portanto, a confiabilidade do sistema passa por todos os níveis, desde a aquisição de um critério de avaliação coerente até a representação do conhecimento.

Para além disso podemos ainda citar dificuldade em encontrar os \textit{datasets} utilizados por trabalhos da literatura \cite{burrows2015}. É muito comum encontrar trabalhos no qual os autores coletaram dados na própria universidade e não as tornam públicas. Além disso, em SAG uma base de dados adequada deve caracterizar o processo avaliativo do professor e constar com relevantes resultados na literatura. Assim, neste trabalho identificamos, testamos e descrevemos uma série de \textit{datasets} na avaliação do método proposto.

\section{Proposta}
\label{cap1-proposta}

Neste trabalho apresentamos um método de avaliação de respostas discursivas curtas através da análise da estrutura textual para produzir modelos avaliativos complexos. Para seu desenvolvimento, identificamos os problemas mais comuns descritos na literatura como deficiências dos sistemas SAG, apresentando uma proposta de solução. Cada um destes problemas é detalhadamente descrito na Seção \ref{cap1-problema}. Portanto, a ideia é desenvolver uma estrutura de reconhecimento do critério avaliativo do professor estabelecendo a relação entre as respostas e as notas atribuídas.


Para atender as demandas encontradas nos trabalhos em SAG utilizamos de técnicas clássicas de \textit{Educational Data Mining} (EDM) \cite{romero2010}, \textit{Machine Learning} (ML) \cite{han2011} e \textit{Natural Language Processing} (NLP) \cite{jurafsky2009}. Apesar do método ter fundamento em modelos linguísticos complexos e comportar questões em diversas linguagens, o avaliamos nas principais bases de dados em \textit{inglês} e \textit{português} da literatura. Dentre os \textit{datasets} observamos 3 tipos de avaliações: notas ordinais, notas discretas e notas contínuas \cite{morettin2010}. Portanto, neste trabalho, estudamos estruturas para identificação das principais respostas do conjunto, reconhecimento do método avaliativo do professor (especialista) e elaboração \textit{feedbacks}.

Para identificação das principais respostas apresentamos um modelo de aprendizado semi-supervisionado. No aprendizado semi-supervisionado o especialista ativamente passa o conhecimento para o algoritmo de classificação \cite{baeza2011}. O algoritmo, por sua vez, utiliza o as informações passadas para criar um modelo que imite o especialista na tarefa. Neste caso, o professor ensina ao sistema seu método avaliativo e, através da atribuição de notas, é formado um modelo que tenta replicar o método para as demais respostas da atividades \cite{romero2010}. Cada uma das respostas enviadas para atividade é considerada uma amostra para o sistema. Dentre todas as amostras, é fundamental que o sistema aprenda cada uma das características das respostas, selecionando as principais por representatividade. Para essa seleção o sistema utiliza de técnicas de otimização e clusterização \cite{everitt2011}. As respostas selecionadas são denominadas de treinamento, pois serão utilizadas para produção dos modelos, enquanto as demais são o conjunto de teste.

No reconhecimento do método avaliativo do professor, modelos são criados para classificação das respostas discursivas. A categorização deve se aproximar ao máximo da tarefa realizada pelo professor, analisando detalhes parecidos na resposta. Portanto, o modelo avaliativo tem por premissa atender as expectativas do professor \cite{pado2021}. Quanto menor a diferença entre a nota dada pelo sistema e a nota atribuída pelo professor, melhor o modelo criado. Consequentemente, os melhores modelos representam melhor a diversidade de notas e respostas com tendência menor de erros. Na gradação das notas, quanto maior a discrepância entre as notas mais críticos são os erros. Sabendo que, entre avaliadores humanos também existe esse erro \cite{artstein2008}. Os dados selecionados para treino do classificador ditam o conhecimento da gradação de notas distribuídas por ele. Portanto, o classificador recebe as características de cada resposta e a sua respectiva avaliação e as compara com as amostras de teste, com notas não conhecidas. Portanto, o modelo de classificação, tomado aqui como avaliador, produz as notas complementares para o conjunto de dados de teste.

Por fim, a elaboração de \textit{feedbacks} e relatórios é fundamental para o suporte ao professor. Em sala de aula, os \textit{feedbacks} são um material que detalha a avaliação para professores e alunos e descrevem o método avaliativo de forma a sanar qualquer dúvida e evidenciar qualquer problema no aprendizado. Por outro lado, na perspectiva da interação do professor com o sistema, os \textit{feedbacks} caracterizam a decisão, descrevem o modelo textual e a equivalência entre respostas. Portanto, em todos os ciclos do sistema esperamos reduzir o esforço de correção do tutor, apresentar resultados de alto nível com o modelo avaliativo e gerar materiais explicativos e completementares de qualidade.

\section{Objetivos} \label{cap1-objetivos}

O objetivo deste trabalho, portanto, é ajustar o modelo de correção criado pela máquina aos padrões estabelecidos pelo professor através da sua avaliação. Para isso, os modelos avaliativos devem compreender o método aplicado pelo professor, categorizando as respostas em classes, níveis ou intervalos contínuos de nota. Segundo a consistência de cada grupo, buscamos reduzir o esforço de correção do professor com a avaliação das respostas que apresentem apenas as principais caracteristicas textuais. Através de padrões bem definidos, esperamos reproduzir o critério avaliativo da questão justificando a classe atribuída através do seu respectivo sumário. Tal sumário, então, são os padrões de cada classe de nota partindo do agrupamento \textit{a priori} das questões. É através desse sumário por nota que recuperamos um possível critério de correção. Desta forma, através do \textit{p}Nota, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor para concentrar-se na verificação de aprendizagem do aluno.

Portanto, temos como âmbito principal a criação de modelos para aproximar o critério avaliativo aplicado ao aluno da definição de padrões de correção e a criação de \textit{feedbacks}. Para isso, estudamos os padrões avaliativos do professor e os métodos de representação do conhecimento encontrado em base de dados de questões discursivas curtas. Para atingir o objetivo geral descrevemos os seguintes objetivos específicos:

\begin{itemize}
\item Organizar os \textit{datasets} públicos da literatura para estabelecer uma comparação com resultados obtidos em estudos correlatos \cite{burrows2015};
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma gramatical, morfológica, semântica, sintática, estatística ou sequencial \cite{galhardi2018a, kumar2019, sahu2020};
\item Interpretar minuciosamente as respostas e o alinhamento do conteúdo, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{jordan2012, saha2018, ding2020};
\item Elaborar e ajustar a avaliação de forma eficiente, assimilando o critério estabelecido pelo professor \cite{zesch2015, condor2020, pado2021};
\item Criar modelos avaliativos robustos, associando as categorias de nota aos padrões textuais \cite{butcher2010, heilman2015, burrows2015};
\item Identificar estruturas textuais para cada categoria de nota, removendo \textit{outliers} e controlando da consistência da classificação \cite{ding2020, filighera2020};
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{higgins2014, funayama2020, pado2021};
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{marvaniya2018, mizumoto2019, suzen2020}.
\end{itemize}

\section{Estrutura do Trabalho}

A seguir são apresentados os conteúdos dessa tese. A proposta é discutida em detalhes através de 5 capítulos. Para além da Introdução, o trabalho é composto dos seguintes capítulos:

\begin{itemize}
\item \textbf{Capítulo \ref{cap-literatura} - Revisão de Literatura:} Apresenta uma breve revisão da literatura sobre métodos de análise e avaliação de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-metodo} - Método:} Define a estrutura do sistema \textit{p}Nota e as formas utilizadas para efetuar de maneira abrangente a análise de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-experimentos} - Experimentos e Resultados:} Descreve por meio de oito \textit{datasets} as diferentes formas de apoio avaliativo, modelagem da relação termo-nota e a formação de \textit{feedbacks} utilizados pelo sistema.

\item \textbf{Capítulo \ref{cap-conclusao} - Conclusão:} Discute as contribuições deste trabalho, conclusões extraídas dos resultados obtidos e as perspectivas de trabalhos futuros.

\end{itemize}