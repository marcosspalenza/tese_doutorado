% ==============================================================================
% Tese - Marcos A. Spalenza
% Capítulo 1 - Introdução
% ==============================================================================
\chapter{Introdução}
\label{cap1-intro}

A Classificação de Documentos é uma abrangente área de estudo que tem característica multidisciplinar. Entre larga escala de documentos, essa área é parte fundamental para redução de esforço de avaliação e aumento exponencial da capacidade analítica humana. Esses estudos compreendem formas de rotular documentos pela caracterização de seu conteúdo de forma objetiva ou subjetiva. A subjetividade da classificação é algo que torna ainda mais complexa a análise, pois os documentos individualmente podem não representar o contexto geral ou garantir a semântica exata dos termos que o compõem. Por isso, a categorização envolve um processo mais complexo do que a simples identificação de termos que estão diretamente associados a uma classe.

No contexto educacional, a avaliação de questões discursivas é um tópico da \textit{Computer-Assisted Asssessment} (CAA) \cite{bogarin2018}. Os estudos em CAA combinam a profundidade textual encontrada nas técnicas de Processamento de Linguagem Natural (NLP) com o vínculo entre o conteúdo e as categorias inerentes à Classificação de Documentos. Nessa linha de estudo encontramos como principal característica a identificação do conteúdo textual relevante para atribuição de notas e produção de feedbacks. Em outra perspectiva, temos o alinhamento da expectativa de nota do professor com seu padrão avaliativo. Então, a nota ideal envolve o reconhecimento do conteúdo relevante e a forma que o professor atribui notas para ele. 

A avaliação é uma etapa básica do ensino, inclusive empregada para garantia da eficiência da aprendizagem. Por meio do método avaliativo o professor mensura a proficiência dos alunos no conteúdo ministrado. A proficiência envolve avaliar o raciocínio segundo a capacidade de resolver problemas, tomar decisões e realizar inferências sobre o assunto \cite{casiraghi2017}. O papel da avaliação, portanto, é diagnosticar, apreciar e verificar o aprendizado dos alunos para que o professor atue no processo de formação de modo a consolidar seu método de ensino \cite{oliveira2005}. Portanto, por meio das avaliações, o professor observa o progresso dos alunos ao assimilar os conteúdos. Com a aplicação dessas avaliações, o professor pode observar a integração dos materiais pedagógicos em sala de aula, para reformulação e aperfeiçoamento das dinâmicas de ensino. Assim, é com o acompanhamento da disciplina e o apoio ao educando que as atividades estabelecem meios de reformular e controlar o processo de ensino-aprendizagem \cite{barreira2006}.

Por meio da avaliação ocorre a identificação dos \textit{gaps} de aprendizado. Esses \textit{gaps} e as ações para contorná-los tornam a estrutura curricular personalizada, com a turma assimilando os temas de acordo com os objetivos da disciplina \cite{biggs1998}. Portanto, os instrumentos e materiais avaliativos são uma forma de consolidar a aprendizagem, indicando quantitativamente e qualitativamente se os alunos assimilaram os principais temas da disciplina. Com o aumento do número de alunos em salas de aula por professor e a popularização dos \textit{Massive Open Online Courses} (MOOCs), o apoio computacional se fez ainda mais necessário. Ao mesmo tempo em que, com a adoção da tecnologia, ampliamos o acesso aos conteúdos e a verificação da aprendizagem, tornando possível a redução da sobrecarga de trabalho dos professores \cite{dunlap2005}.

Com a mediação tecnológica, se consolidou a aplicação das atividades em maior escala. Desse modo, os Ambientes Virtuais de Aprendizagem (AVA) \cite{maquine2020} se tornaram plataformas de suporte para aulas em turmas presenciais e a distância \cite{raes2020}. Com isso, o professor ganha também suporte na criação, na avaliação, na recomendação e na visualização de dados educacionais impactando diretamente o acompanhamento do currículo do aluno \cite{paiva2012}. Assim, com as ferramentas de apoio, o tutor verifica a aptidão dos estudantes, de forma individual ou coletiva, para melhorar a experiência da disciplina.

A avaliação é caracterizada pela união de uma série de aspectos que caracterizam o desenvolvimento do aluno. Podemos citar como um desses, a habilidade de escrita e comunicação sobre o tema. Alinhadas a essa habilidade, as questões discursivas indicam como os estudantes produzem um discurso em torno de um tópico. Entretanto, as questões discursivas incluem uma série de técnicas de escrita, partindo de respostas de preenchimento com poucas palavras até a produção de longas redações. Neste trabalho enfatizamos o suporte ao professor na avaliação de respostas discursivas curtas. Ainda assim, encontramos \textit{datasets} de questões discursivas curtas com diferentes modelos de resposta e avaliação. Definimos como respostas curtas conjuntos textuais de até três sentenças, compostos por até cem palavras. Para caracterizar as respostas discursivas curtas, é apresentada na Tabela \ref{tab-ptasag46-exemplo} a atividade de exemplo \textit{PTASAG-46}.

\begin{table}[!b]
\centering
\caption{Exemplo de respostas curtas com amostras da atividade 46 do \textit{dataset PTASAG}.}
\label{tab-ptasag46-exemplo}
\begin{tabular}{ r | p{14cm}}
\hline
\multicolumn{2}{l}{\textbf{PTASAG}} \\ \hline
\multicolumn{2}{c}{\textbf{Atividade 46}} \\ \hline 
\multicolumn{2}{l}{\textit{Quais são as diferenças entre veias e artérias?}} \\ \hline
 \# & Resposta \\ \hline
 4 & veias são meio que canos que levam o sangue aos orgãos enquanto as artérias são os canos que levam o sangue ao coração \\
 8 & Veias: sao mais finas. Artéria: são mais grossas \\
 14 & As veias levam o sangue sem oxigênio e as artérias levam o com oxigênio \\
 31 & As artérias tem a função de eliminar o sangue sujo enquanto as veias fazem o contrário \\
 49 & As veias carregam o gás carbônico. As artérias carregam o oxigênio \\
 61 & Artéria passa ar e na veia passa sangue \\
 74  & As artérias bombeam o sangue para todo o corpo e as veias levam o sangue de volta ao coração \\
 144 & Veias passam sangue pouco oxigenado e artérias passam o sangue mais oxigenado. \\
 154 & Veia transporta gás carbônico e artéria o gás oxigênio. \\
 161 & as artérias circulam o ar e as veias circulam o sangue. \\
 211 & A diferença é a valvula \\
 296 & Veias: é um vaso sanguíneo que transporta o sangue em direção ao coração. Artérias: Vasos sanguíneos que carregam sangue do coração para todas as partes do corpo. \\
 451 & Veias: sangue venoso. Artéria: sangue arterial. \\
 520 & A veia é fina já a artéria é grossa pois faz as trocas e leva sangue para o coração \\ 
 570 &  Artérias são mais grossas e são maiores, possuem maior fluxo de sangue e passa gases como O2 e CO2, já as veias são mais finas tem menor fluxo, mas também passa O2 e CO2 \\
\\
\hline
\hline
\end{tabular}
\end{table}


Na Tabela \ref{tab-ptasag46-exemplo}, é apresentada uma questão com seu enunciado e uma amostra com 15 respostas, seguidas pelo identificador do estudante que realizou cada submissão. Essa questão será utilizada para ilustrar as questões discursivas curtas. As respostas foram enviadas para a questão \textit{PTASAG-46}, cujo enunciado é ``Quais são as diferenças entre veias e artérias?''. Como as amostras destacam, temos nessa questão um conjunto de respostas de diferentes tamanhos, formas e desenvolvimento segundo o tópico. Portanto, como o próprio exemplo indica, a liberdade de escrita e diversidade de conteúdos é uma característica comum dos \textit{datasets}. Isso ocorre pois há livre produção textual por parte dos estudantes nas questões abertas. Assim, a escrita aberta é expressa pelas diferentes formas que os estudantes se referem a um ou mais modelos de resposta. 

Mesmo com diversas linhas de resposta, a avaliação deve considerá-las durante a representação de conteúdo e o mapeamento de conceitos. Partindo por critérios objetivos, o método avaliativo deve contemplar todas as perspectivas dos participantes. Nesse contexto, uma forma consistente de resposta contém total ou parcialmente as principais componentes avaliativas. No caso, dentro do nosso exemplo, as respostas deveriam contemplar \textit{a condução do sangue entre tecidos e o coração para limpeza de toxinas}. Em destaque, segue o texto completo criado pelo professor: 

\begin{quote}
\interlinepenalty=10000
\textit{Quando o coração bombeia o sangue, ele bombeia este sangue diretamente nas artérias com grande pressão, para que as artérias possam conduzir o sangue na direção dos tecidos. As veias são responsáveis por conduzir o sangue de volta ao coração e removem as toxinas dos tecidos para que elas sejam eliminadas.}
\end{quote}

Fica evidente no texto elaborado pelo professor que a essência da resposta deve, pelo menos, tangenciar fatores como a \textit{troca do oxigênio} e os \textit{ciclos de transferência do sangue entre coração e corpo}. Mesmo que as respostas não sejam iguais à proposta do professor, atribuímos a nota máxima quando são vinculados corretamente os \textit{ciclos arteriais e venosos}. Isso ocorre pois, na aplicação de questões discursivas curtas, existe uma expectativa de convergência entre respostas. Essa convergência torna as respostas complementares aos enunciados que proporcionam uma ou poucas trilhas de resposta. Portanto a convergência não é necessariamente a simetria textual entre palavras, como restrição textual nas respostas abertas. Na verdade, essa convergência designa tendência para respostas elaboradas de forma impessoal e direcionadas ao tema. As respostas impessoais são caracterizadas pela ausência de marcas pessoais, sendo diretas quanto à expectativa com relação ao que está descrito no enunciado. Na sua construção, o estudante deve seguir uma das trilhas do tópico abordado, caso contrário não atende essa expectativa de resposta.


Nesse ponto é importante a definição de quatro níveis diferentes interpretativos das respostas. São eles: os \textit{modelos de resposta}, a \textit{expectativa de resposta}, as \textit{respostas candidatas} e, por fim, os \textit{padrões de resposta}. 


Com o alinhamento das respostas com o tópico, podemos inferir que existem modelos que associam o tema abordado com o contexto da resposta. Então, chamamos de \textit{modelos de resposta} a convergência entre o que está na resposta com o tema. Descrevemos então \textit{modelo de respostas} como a tendência das respostas elaboradas pelos estudantes apresentarem entre si certo índice de similaridade.

Com a existência de modelos objetivos que vinculam respostas correspondentes, podemos afirmar também que a avaliação segue uma \textit{expectativa de resposta} do avaliador. Por meio desse índice de similaridade, afirmamos que existe um nível de atingimento de resposta que permite a gradação em diferentes níveis de nota. Portanto, o atendimento da \textit{expectativa de resposta} denota quais são as características relevantes que levam respostas divergentes para  diferentes avaliações. Portanto, é a \textit{expectativa de resposta} que compõe o alinhamento entre o texto dos estudantes, o tema e as notas atribuídas. Assim, respostas que seguem um mesmo padrão, ou modelo, devem receber notas equivalentes caso nenhum fator externo esteja envolvido no processo avaliativo. Podem ser citados como exemplo de um fator externo de avaliação os casos de plágio \cite{campana-filho2017}. Então, isso garante que, nas devidas proporções, os estudantes que seguem uma mesma linha de resposta recebam avaliações similares.

A partir da \textit{expectativa de resposta} com a definição dos conteúdos que diferenciam e determinam as faixas de nota, podem ser determinadas as \textit{respostas candidatas}. As \textit{respostas candidatas} são aquelas produzidas pelo próprio professor como uma definição da \textit{expectativa de resposta} de acordo com o que está disposto no enunciado da atividade. Portanto, são essas que caracterizam a avaliação em um exemplo textual, tal qual o que foi produzido pelos estudantes. Elas indicam o que compõe uma resposta completa para a questão na visão do avaliador, como um referencial. O critério avaliativo e a \textit{resposta candidata} não são determinísticos e, quando existe algum nível de subjetividade textual, destacam divergências entre os avaliadores especialistas \cite{pado2021}.

Nesses três níveis, há formação implícita de um modelo, em que é envolvida diretamente a construção textual do aluno e do professor dentro do critério avaliativo. Entretanto, com sistemas de apoio ao professor adiciona-se mais um nível analítico. Sob a perspectiva do sistema há os \textit{padrões de resposta}, que indicam o reconhecimento contextual e linguístico das respostas. Nesse nível, o sistema realiza a análise da questão de forma horizontal. Essa etapa, identifica características relevantes do critério segundo a \textit{expectativa de resposta}. Ao se aproximar do que é a expectativa do avaliador, o sistema aprende vínculos entre notas e as partículas textuais que compõe os \textit{modelos de resposta}. Assim, os \textit{padrões de resposta} são critérios objetivos do sistema, compostos pela correspondência entre respostas e notas.

Com essas quatro perspectivas sobre o conjunto de respostas, designamos a forma que cada entidade participante do processo avaliativo observa a diversidade textual. Portanto, na visão dos estudantes, temos a convergência das respostas na formação de \textit{modelos}. Na análise do professor, os modelos têm viés avaliativo, e esse viés é representado por meio da \textit{expectativa de resposta}. Por outro lado, quando disponíveis, as \textit{respostas candidatas} atuam para reduzir o nível de abstração das expectativas do avaliador, apresentando-a via exemplos.  E, por fim, na ótica do sistema, a equivalência entre as estruturas textuais indicam \textit{padrões}, formados por grupos de resposta com as mesmas características.

O processo avaliativo é por definição algo complexo, principalmente pela relação entre os documentos textuais e a nota atribuída. O processo inclui analisar todo contexto detalhadamente para atribuição de notas, produção de \textit{feedbacks} e revisão dos conteúdos. Neste ainda enfatizamos a diversidade textual. A diversidade textual inclui as diferentes formas de linguagem adotadas para produção das respostas. Isso inclui as variações consideradas no atingimento do critério avaliativo. Assim a automação do processo de análise textual, mesmo que parcial, inclui compreender as tendências de resposta de acordo com o conteúdo abordado. 

Pelo caráter multidisciplinar, as respostas curtas são analisadas segundo detalhes da produção textual, como sua completude e seu direcionamento ao tema. Assim, o aluno é avaliado pela coerência da resposta, pela capacidade de sumarização e pela aplicação da linguagem. Aliado a isso, o papel do sistema é dado pela sua capacidade de reconhecer padrões de escrita, com a análise de estruturas de linguagem na identificação do que é correspondente ao conteúdo ministrado. Para isso, são necessários altos níveis de interpretação textual. O objetivo geral dos sistemas de CAA é reduzir o esforço avaliativo do professor durante esses procedimentos avaliativos. 

O reconhecimento das estruturas que formam a linguagem escrita é fundamental para a descoberta dos \textit{padrões de resposta}. Cada resposta, como um documento textual, é composta por uma série de características. Cada característica é extraída de acordo com um aspecto dessa estrutura, seja ela gramatical, morfológica, semântica, sintática, estatística ou sequencial \cite{kumar2019}. Portanto, o reconhecimento de padrões passa pela identificação das características mais relevantes nas respostas que compõem a avaliação de uma atividade. A quantidade de características em média extraídas por atividade nos \textit{datasets} utilizados neste trabalho é apresentada na Tabela \ref{tab-features}.

% TABELA CARACTERISTICAS
\begin{table}
\centering
\caption{Componentes observadas nas respostas de cada \textit{dataset}.}
\label{tab-features}
\begin{tabular}{|r | r r r|} \hline
\textit{Dataset} & Características & Palavras & Caracteres \\
\hline
 SEMEVAL2013 Beetle & 98 & 10 & 50 \\
 SEMEVAL2013 SciEntsBank & 110 & 13 & 64 \\
 Kaggle ASAP-SAS & 2932 & 43 & 236 \\
 Powergrading & 178 & 4 & 20 \\
 UK Open University & 418 & 10 & 55 \\
 University of North Texas & 140 & 20 & 107 \\
 Kaggle PTASAG & 906 & 13 & 72 \\
 Projeto Feira Liter{\'a}ria & 123 & 8 & 40 \\
 VestUFES & 1391 & 92 & 536 \\
\hline \hline
\end{tabular}
\end{table}

Como é destacado na Tabela \ref{tab-features}, mesmo sobre um tipo específico de questão, temos variações importantes no modelo de resposta. Apesar de todos os conjuntos se enquadrarem nas especificações de respostas já citadas, são evidentes as diferenças entre \textit{datasets}. Enquanto majoritariamente temos conjuntos com respostas bem concisas (menores que 20 palavras), temos \textit{VestUFES} e \textit{Kaggle ASAP-SAS} mais descritivos e, possivelmente, com enunciados mais abstratos. Diante do escopo delimitado para as respostas, sobressaem alguns desafios na compreensão computacional da linguagem e dos métodos avaliativos. Desse modo, é fundamental a produção de modelos avaliativos computacionais que demonstrem fluência na análise da linguagem e conteúdo. Portanto, o sistema é composto por modelos avaliativos e deve se aproximar ao máximo do critério do professor ao realizar inferências.

Sabendo dos desafios de uma aplicação em CAA, propõe-se uma aplicação de \textit{Machine Learning} (ML) para o reconhecimento de padrões textuais encontrados nas questões discursivas. Nela, utilizamos técnicas de \textit{Active Learning} para compor o processo de anotação do especialista, mesclando com ciclos de \textit{Unsupervised} e \textit{Supervised Learning}. \textit{Unsupervised Learning} é aplicado para identificação da distribuição espacial e amostragem. Enquanto isso, \textit{Supervised Learning} é aplicado para construção de avaliadores alinhados ao reconhecimento de padrões textuais. Assim, o sistema chamado \textit{p}Nota, apresenta uma combinação de técnicas de pré-processamento, clusterização, amostragem, classificação e produção de \textit{feedbacks} para criar um modelo avaliativo de referência dado o critério do professor.

A técnica aplicada na atribuição de notas deve seguir rigorosamente as características da avaliação realizada pelo professor. Para isso, o modelo de avaliação de respostas discursivas curtas, ou \textit{Short Answer Graders} (SAG), tem três papéis principais. O primeiro papel é a identificação dos padrões de resposta. O segundo é reproduzir o critério avaliativo do professor por meio de sua técnica de avaliação. Por fim, o terceiro compõe a descrição do método, com a criação de \textit{feedbacks} para todos os participantes \cite{arter2006, spalenza2016a}.


\section{Problema} 
\label{cap1-problema}

Na literatura dos SAG, encontramos uma série de problemas que caracteriza a evolução da pesquisa durante os anos. Em geral, a característica principal dos problemas é a relação entre conteúdo textual e a atribuição de nota, nem sempre de forma objetiva. Com isso, os avaliadores devem aprender o método do professor como especialista, identificando padrões de resposta que levam a cada uma das categorias de nota. Assim, além de compreender a linguagem, os modelos precisam identificar o vínculo de cada resposta com o tema da questão. Nessa linha, a expectativa é a criação de modelos SAG cada vez mais similares ao formato de avaliação do professor. Portanto, com forte aderência aos desafios de NLP, os SAG buscam estabelecer critérios na atribuição de nota similares aos do professor \cite{pado2021}. Mesmo sendo um trabalho realizado há décadas \cite{burrows2015}, a literatura dos modelos SAG descreve uma série de problemas em aberto, pouco estudados até o momento.

Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto na forma bruta \cite{perez-marin2009}. Neles, a atribuição de notas é dada pela compatibilidade exata entre texto e chave de resposta. São modelos sem flexibilidade e resolvem apenas problemas simples. Essa linha de trabalho falhou por inúmeras vezes na padronização e na identificação de sinônimos \cite{leffa2003}. Problemas similares aconteceram com as técnicas que usavam apenas as métricas de resposta, como a quantidade de palavras ou frases que cada resposta contém. Mas foram essas linhas de trabalho que identificaram \textit{gaps} importantes na análise de conhecimento contextual e na formulação individual das respostas. Por conta disso, há nos algoritmos SAG atuais estudos mais profundos na construção linguística \cite{filighera2020}.

Posteriormente, os sistemas ganharam um pouco de flexibilidade textual com extração de informação e expressões regulares. Porém, mesmo esses sistemas falham para identificar a paridade dos termos dentro da linguagem e na adaptação em diferentes contextos. Atualmente a área já avalia o texto de forma mais robusta, combinando NLP e ML. Nos últimos cinco anos também começaram a figurar alguns estudos comparativos, adotando técnicas de \textit{Deep Learning} (DL) \cite{bonthu2021}. Porém, mesmo com técnicas mais robustas, até o momento existe essa preocupação com a profundidade do aprendizado, em tradução literal para ``\textit{depth of learning}'' \cite{burrows2015}. A profundidade indica a capacidade de recuperar a informação do texto e atuar na atribuição de notas segundo o contexto. Portanto essa é a característica dos modelos SAG que define a produção de modelos complexos de correção, interpretando computacionalmente o conteúdo de respostas curtas em textos de escrita livre.

Diretamente associada à interpretação textual, existe a busca de convergência entre as respostas. Nesse aspecto há o problema para extração do viés em respostas factuais com múltiplos contextos. A objetividade das respostas é fundamental para contextualização, atrelada a compreensão do algoritmo para fatos corretos e incorretos. Assim, as questões devem ter convergência em algum nível da interpretação textual. Por conta disso, existe ainda maior complexidade para lidar com questões que resultam em respostas opinativas, individuais ou subjetivas \cite{bailey2008}. Nesse aspecto, é esperado que o sistema, de forma independente do conteúdo do professor, lide com a liberdade de escrita do estudante e analise a convergência entre as respostas na tentativa de recuperar padrões compatíveis \cite{saha2018, lui2022}.

Em geral, para além do reconhecimento de padrões de resposta, ainda existe o alinhamento entre o conteúdo das respostas e o critério avaliativo. De forma geral, esse fator é um reflexo das referências utilizadas na criação do modelo avaliativo \cite{krithika2015}. Para compreender o papel do especialista, o sistema deve seguir o professor em seu padrão de avaliação, tentando replicá-lo \cite{jordan2012, funayama2020}. Nessa situação, é complexo ao sistema se adaptar para respostas que têm o alinhamento correto mas que recebem uma distinção nas notas. Assim, apesar da escolha de palavras alinhadas com um determinado modelo de resposta, é essencial que o sistema forme vínculos entre padrões de avaliação e de respostas para criação de modelos avaliativos complexos \cite{higgins2014}. É fundamental portanto, a extração do critério avaliativo do professor, para além de um sistema tradicional de reconhecimento de padrões.

Ainda sobre a expressão da nota atribuída a cada resposta, existe também a preocupação com classificações incorretas. Em todas as formas, é determinante que a atribuição de notas seja coerente e justificável, em especial na adoção dos SAG \cite{funayama2020}. Assim, é recorrente o uso de formas que remontam as componentes de resposta que levam a uma correção, seja via regras de associação, expressões regulares ou extração de características textuais \cite{chakraborty2017, kumar2019}. Nessa linha, é essencial que os sistemas compreendam o conteúdo sem avaliações tendenciosas \cite{azad2020}, realizando uma análise ampla do conteúdo anotado.

Aliado a isso, para a garantia da isonomia no processo avaliativo, devemos identificar quando tais incoerências ocorrerem. Existem níveis de erro tanto durante a aplicação do modelo de avaliação quanto na anotação de respostas, algo comum até entre dois especialistas \cite{artstein2008, pado2021}. Mas é essencial minorar a diferença cada vez mais entre o modelo do especialista e o modelo de avaliação automática \cite{condor2020}. Para além da necessidade de justificativa a cada nota atribuída, ainda é possível ressaltar a necessidade de reconhecer \textit{outliers} para que, equivocadamente, este não se torne influente no método avaliativo \cite{ding2020}. Nessa dinâmica, ressalta-se a importância em isolar comportamentos anômalos do método avaliativo para que não influencie o comportamento geral do modelo automático. Sabendo disso, um critério avaliativo robusto deve ponderar quais componentes textuais formam o modelo de avaliação. A aquisição desse modelo é feita por meio da identificação do formato avaliativo do professor em uma série de respostas. 

Ainda é necessário adicionar a tal problema, o desbalanceamento entre os níveis de nota e a baixa amostragem \cite{dzikovska2012, lui2022}. Assim, geralmente, as primeiras aplicações de uma atividade produzem bases de dados com pequenas quantidades de amostras e com grande diferença dentro dos grupos de nota. Por conta disso, uma série de trabalhos faz uso de descritores do padrão avaliativo, como as expressões regulares, regras ou quadros de \textit{rubrics}, para interpretar a forma como professor constrói seu padrão de avaliação \cite{butcher2010, mohler2011, ramachandran2015a, condor2021}. Porém, isso contrapõe a proposta de reduzir o esforço avaliativo do professor, se for considerada a necessidade de produção de qualquer conteúdo extra sobre seu critério \cite{zesch2015, horbach2018}. É importante, portanto, a melhoria das técnicas de aprendizado, amplificando a aquisição de conhecimento pelos exemplos. Por meio dessa melhoria prioriza-se o esforço já aplicado na anotação para remontar o critério avaliativo.

Um contraponto ao aprendizado por exemplos é lidar com a amplitude da linguagem durante a atribuição de notas. Isso acontece porque os padrões desconhecidos podem conter \textit{outliers} que recebem um modelo próprio de avaliação \cite{filighera2020}. Isso significa que, dado nível de subjetividade da questão e a diversidade textual, o modelo deve aprender formas de avaliar padrões não mapeados. Assim, a seleção de amostras é fundamental para conectar a diversidade textual aos níveis de nota. Isso torna necessárias aos sistemas a análise da distribuição de amostras e a anotação guiada das respostas, conectando as notas ao tópico abordado nos documentos textuais \cite{marvaniya2018}.

Como consequência da representação textual das notas, na esfera avaliativa, há um problema na criação de modelos complexos entre termos e classes \cite{ramachandran2015a}. Sendo a nota de vínculo interpretativo, em aspectos gerais, pode-se dizer que existe apenas a aproximação ou correlação entre as formas de avaliação. A correlação indica que os especialistas concordam e seguem as mesmas diretrizes na atribuição das notas \cite{artstein2008}. Por outro lado, isso significa também que cada especialista pode ter análises individuais do conjunto de respostas. Então, é o objetivo de um avaliador, em especial nos modelo SAG, compreender e incorporar detalhes sutis do texto em seu critério de avaliação \cite{horbach2018, condor2021}. Portanto, a relação termo-classe deve ser dinâmica e extrair o modelo que melhor atenda às expectativas do professor, em especial com o fato de ela ser passível de revisões \cite{spalenza2016a}.

Quando se olha o conjunto de respostas, é fundamental partir da sua formação por aspectos estruturais. Por consequência, além da análise detalhada da forma de escrita, é fundamental uma extensa capacidade analítica do conteúdo \cite{saha2018}. Isso significa que, além do nível textual é desejável que a análise seja feita em vários níveis, incluindo verificação morfológica, semântica e sintática de cada resposta \cite{sakaguchi2015, riordan2019, sahu2020}. Desse modo, a aquisição de informação do texto deve maximizar o conhecimento na formação dos modelos, para compreensão do tema e da estrutura de escrita. Somadas a isso, algumas propostas vão além e ainda exploram a conexão semântica entre respostas, questões e domínios \cite{dzikovska2013, saha2019}.

A confiabilidade dos SAG também é constituída pela soma dos fatores aqui elencados. Superficialmente é possível associar esse problema à divergência de notas entre avaliadores. Porém, em um aspecto amplo, a confiabilidade do sistema inclui desde o reconhecimento do critério avaliativo até a criação de justificativas de nota por meio de modelos descritivos de \textit{feedback} \cite{kumar2019}. O papel dos modelos de \textit{feedback} vai além de descrever o que o sistema observou na avaliação. Ele declara a todos os participantes a atribuição de notas de acordo com a composição das respostas \cite{marvaniya2018, bernius2022}. Portanto, a confiabilidade do sistema passa por todos os níveis citados de representação do conhecimento.

Por fim, ainda existem complicações para encontrar \textit{datasets} públicos na literatura \cite{burrows2015}. Os poucos disponíveis têm métricas específicas de comparação, apresentando problemas ao estabelecer comparações com a literatura e aumentando a dificuldade de replicar o que foi realizado nos demais estudos. Desse modo, em SAG uma base de dados adequada deve simular o processo avaliativo do professor, dando visibilidade a comparações e resultados encontrados na literatura.


\section{Proposta}
\label{cap1-proposta}

Conforme os relatos encontrados na literatura dos SAG, é apresentado neste trabalho um sistema que propõe uma análise das estruturas textuais para produção dos modelos avaliativos complexos mencionados. Portanto, há uma proposta que atende várias deficiências dos SAG. Cada um desses problemas foi detalhadamente descrito anteriormente, na Seção \ref{cap1-problema}. Portanto, a ideia é propor, desenvolver e analisar um método de reconhecimento do critério do professor por meio da avaliação das estruturas textuais, estabelecendo relações entre as respostas e suas respectivas notas.

Para atender as demandas encontradas nos trabalhos em SAG são utilizadas técnicas clássicas de \textit{Educational Data Mining} (EDM) \cite{romero2010}. Apesar de o método ter fundamento em modelos linguísticos complexos e comportar questões em diversas linguagens, a avaliação conta com as principais bases de dados em \textit{inglês} e \textit{português} da literatura. Nesses \textit{datasets} são observados três tipos de avaliações: notas ordinais, notas discretas e notas contínuas, ao qual demandam de tratamentos estatísticos diferentes \cite{morettin2010}. Portanto, neste trabalho, são estudadas estruturas para identificação das principais respostas do conjunto, reconhecimento do método avaliativo do professor (especialista) e elaboração de \textit{feedbacks}.

Para identificação das principais respostas é apresentado um modelo de \textit{Active Learning}. Em \textit{Active Learning} o especialista ativamente passa o conhecimento para o algoritmo de classificação \cite{silva2007, miller2020}. O algoritmo, por sua vez, utiliza as informações passadas para criar um modelo que replica o especialista na tarefa. Nesse caso, o professor ensina ao sistema seu método avaliativo, e, por meio da atribuição de notas, é formado um modelo que realiza as avaliações das demais respostas \cite{romero2010}. Cada uma das respostas enviadas para atividade é considerada uma amostra para o sistema. Entre todas as amostras, é fundamental que o sistema aprenda em detalhes as diferentes características encontradas nas respostas, identificando sua representatividade. Para essa seleção o sistema combina técnicas de otimização e clusterização \cite{everitt2011, spalenza2019}. As respostas selecionadas são denominadas treinamento, pois serão utilizadas para produção dos modelos, enquanto as demais formam o conjunto de teste. O conjunto de teste determina o desempenho do sistema como avaliador.

No reconhecimento do método avaliativo do professor, modelos são criados visando à atribuição de notas para respostas discursivas. Essa etapa de classificação deve se aproximar ao máximo da tarefa realizada pelo professor, analisando a similaridade entre as respostas. Quanto menor a diferença entre a nota dada pelo sistema e a nota atribuída pelo professor, melhor será o modelo criado. Consequentemente, os melhores modelos representam com coerência a diversidade de notas e respostas, apresentando menor índice de erros. Na gradação das notas, quanto maior a discrepância entre as notas mais críticos são os erros. Os dados selecionados para treino do classificador ditam o conhecimento da gradação de notas distribuídas por ele. Assim, o classificador recebe as características de cada resposta e a sua respectiva avaliação e as compara com as amostras de teste, sem notas determinadas. Portanto, o modelo de classificação, tomado aqui como avaliador, produz as notas complementares para o conjunto de dados de teste.

Por fim, a elaboração de \textit{feedbacks} é fundamental para o suporte ao professor, com a descrição do método avaliativo e a sumarização dos resultados. Em sala de aula, os \textit{feedbacks} são um material que detalha a avaliação para professores e alunos, de forma a sanar dúvidas e evidenciar \textit{gaps} no aprendizado. Por outro lado, na perspectiva da interação do professor com o sistema, os \textit{feedbacks} caracterizam a decisão e descrevem o modelo textual e a equivalência entre respostas \cite{bernius2022}. Portanto, em aspectos gerais, todos os ciclos do sistema atuam para reduzir o esforço de correção do tutor, apresentar resultados de alto nível com o modelo avaliativo e gerar materiais complementares explicativos sobre os níveis de nota.

\section{Objetivos} \label{cap1-objetivos}

O objetivo deste trabalho é reduzir gradativamente o esforço de correção do professor por meio de um modelo de avaliação de respostas discursivas curtas. Para isso, é essencial o aprendizado do critério avaliativo do professor por meio de exemplos, reduzindo o esforço necessário em mais aplicações do mesmo conjunto de respostas. Assim, esperamos criar modelos avaliativos que compreendam as estruturas de linguagem, o alinhamento ao tópico de cada resposta e a forma com a qual é feita a atribuição de notas pelo especialista. Dessa forma, com o \textit{p}Nota, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor para se concentrar na verificação de aprendizagem do aluno.

Temos, dessa forma, como objetivo principal aprender o comportamento avaliativo que vincula uma nota para determinadas estruturas textuais que compõem as respostas dos estudantes. Para isso, esperamos reproduzir por meio do \textit{p}Nota padrões avaliativos complexos, tornando-se um avaliador correspondente ao professor.

Para isso, estudamos as diferentes formas de construção de respostas discursivas curtas, a identificação de componentes relevantes e a representação do conhecimento em questões discursivas curtas. Nessa linha, para atingir o objetivo geral descrevem-se os seguintes objetivos específicos:

\begin{itemize}
\item Organizar os \textit{datasets} públicos da literatura para estabelecer uma comparação com resultados obtidos em estudos correlatos \cite{burrows2015};
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma gramatical, morfológica, semântica, sintática, estatística ou sequencial \cite{galhardi2018a, kumar2019, sahu2020};
\item Interpretar minuciosamente as respostas e o alinhamento do conteúdo, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{jordan2012, saha2018, ding2020};
\item Elaborar e ajustar a avaliação de forma eficiente, assimilando o critério estabelecido pelo professor \cite{zesch2015, condor2020, lui2022};
\item Criar modelos avaliativos robustos, associando as categorias de nota aos padrões textuais \cite{butcher2010, heilman2015, burrows2015};
\item Identificar estruturas textuais para cada categoria de nota, removendo \textit{outliers} e controlando da consistência da classificação \cite{ding2020, filighera2020};
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{higgins2014, funayama2020, pado2021};
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{mizumoto2019, suzen2020, bernius2022}.
\end{itemize}


\section{Estrutura do Trabalho}

A seguir são apresentados os conteúdos desta tese. A proposta é discutida em detalhes em cinco capítulos. Para além da Introdução, o trabalho é composto dos seguintes capítulos:

\begin{itemize}
\item \textbf{Capítulo \ref{cap-literatura} - Revisão de Literatura:} apresenta uma breve revisão da literatura sobre métodos de análise e avaliação de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-metodo} - Método:} define a estrutura do sistema \textit{p}Nota e as formas utilizadas para efetuar de maneira abrangente a análise de respostas discursivas curtas.

\item \textbf{Capítulo \ref{cap-experimentos} - Experimentos e Resultados:} descreve por meio de nove \textit{datasets} as diferentes formas de apoio avaliativo, a modelagem da relação termo-nota e a formação de \textit{feedbacks} utilizados pelo sistema.

\item \textbf{Capítulo \ref{cap-conclusao} - Conclusão:} discute as contribuições deste trabalho, conclusões extraídas dos resultados obtidos e as perspectivas de trabalhos futuros.

\end{itemize}
