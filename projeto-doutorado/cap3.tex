%\pagestyle{empty}
%\cleardoublepage
%\pagestyle{fancy}
%\pagenumbering{arabic}

\section{Problemática}\label{cap3}

Na literatura da Avaliação Assistida por Computadores encontramos alguns problemas do tópico de avaliação automática de questões discursivas que temos interesse em trabalhar neste projeto. Apesar de ser um estudo realizado há décadas, na avaliação automática de questões discursivas encontram-se desafios pouco abordados e dados como problemas do processo de avaliação pela máquina. Nos primeiros sistemas, a modelagem de questões discursivas era um trabalho realizado com o texto bruto. A partir disso, a busca por equivalência entre a resposta esperada e o texto dos estudantes falhou por inúmeras vezes na padronização dos documentos e na identificação de sinônimos \cite{leffa2003}. O estudo dessa problemática derivou discussões em torno da identificação do conhecimento nos documentos escritos pelo aluno, realizada atualmente em boa parte dos algoritmos. Técnicas de Aprendizado de Máquina, Estatística, Processamento de Linguagem Natural, Expressões Regulares e Reconhecimento de Padrões, dentre outras, foram testadas para a recuperação dos diferentes modelos de resposta e avaliação.

Na revisão da literatura de avaliação automática de questões discursivas produzida por \citeonline{burrows2015}, os autores reúnem 37 trabalhos realizados na área. Durante essa revisão, o autor destaca o problema da  profundidade do aprendizado, em tradução literal de ``\textit{depth of learning}'', separando as atividades em dois grupos: de reconhecimento e de recuperação. Tais modelos têm diferentes intúitos na aquisição de informação do aluno o que gera diferentes modos de processamento. No Brasil, conhecemos essas por questões abertas e fechadas, nomenclaturas também citadas pelos autores. Essa divisão estabelece a diferença entre as atividades que exploram apenas a necessidade de identificação e organização de conteúdo e as que dependem de construção de ideias visando respostas próprias e originais. Definimos, então, a liberdade do aluno na criação do seu conjunto de resposta como a chave para separar atividades que necessitem de maior ou menor conhecimento factual, ou respectivamente, questões abertas ou fechadas.

Um problema com esse viés é reagir às questões discursivas factuais e opinativas da forma adequada \cite{bailey2008}. É esperado que o sistema lide com a liberdade de escrita do aluno recuperando o conteúdo. A forma aqui proposta para contornar esse problema de identificação do critério avaliativo parte de interações com o especialista. Essas interações são requisições de correção para buscar avaliações específicas de padrões textuais das respostas. Esse processo seleciona documentos que indiquem certo grau de distinção por grupo, resultante de uma clusterização inicial \cite{oliveira2014}. Coletamos assim a classificação dada para os itens elencados como relevantes pelo sistema em cada \textit{cluster} para continuidade do processo avaliativo.

Desta forma, a modelagem semiautomática do processo permite que encontremos subgrupos de respostas por \textit{cluster}. A partir daí devemos encontrar qual é o critério avaliativo do professor, sem precisar de uma chave de resposta, dado até o momento como necessário \cite{butcher2010, mohler2011, ramachandran2015a}. Alguns procedimentos de extração de informação e análise de padrões aqui propostos na Seção \ref{cap4} visam remontar o critério do professor e otimizando o processo de correção automática.

O problema passa da necessidade de avaliação para o aumento do número de padrões à serem avaliados pelo professor para relacionar conteúdo com classificação. \citeonline{butcher2010} citam alguns problemas no processo avaliativo automático do \textit{FreeText Author}. O primeiro, a omissão do padrão de avaliação, já foi discutido acima. O segundo é a identificação de palavras incorretas associando-as com sua forma correta. O terceiro problema, conforme os autores, é a necessidade de identificação estrutural da sentença. A quarta dificuldade listada é o tratamento de classificações incorretas do especialista. O quinto problema é o conflito de um padrão correto de resposta com uma avaliação dada como incorreta. A relação entre a quarta e a quinta dificuldade listada é apresentada pelos autores como um sexto problema, dada pela inconsistência no módulo de interpretação textual do sistema, afetando diretamente a sua confiabilidade como avaliador.

Os problemas linguísticos listados por aquele autor (2º e 3º) de reconhecimento estruturais e semânticos ainda não são trabalhados de forma explícita na nossa proposta. A ferramenta alvo deste projeto faz análises diretas na frequência de ocorrência das palavras e realiza pré-processamentos para tornar grupos de termos e documentos equivalentes. Segundo \citeonline{ramachandran2015a}, a avaliação com base na sintaxe, ortografia ou organização não são suficientes para as questões discursivas curtas. Tendo isso em vista, o protótipo do sistema visa expandir a implementação de módulos linguísticos independentes, tal como o \textit{stemming}, a remoção de \textit{stopwords} e a separação por \textit{n-grams} já testadas em português e inglês.

Após os módulos linguísticos, os demais problemas serão cautelosamente trabalhados através de metodos de recuperação da informação. Assim, o 4º problema esclarece a dificuldade em separar possíveis \textit{outliers} das informações relevantes que foram apresentadas em uma única ou poucas ocasiões no banco de dados. Nosso método de contornar essa adversidade é dada pelo envio de padrões distintos para a avaliação humana, em busca de referências ao conteúdo. Desta forma, a ferramenta trabalha cada nota como um rótulo dado pelo especialista, criando um modelo mais detalhista do que a análise de uma resposta candidata elaborada pelo professor.

No 5º problema, sobre a localização de padrões de avaliação incorretamente classificados pelo especialista, há um impacto grave na adaptabilidade da máquina como avaliador. Esse tópico ainda não é trabalhado no protótipo, ao qual esperamos adequa-lo para interpretar alterações na avaliação para ajustar seu modelo de classificação, extraindo cada alteração como conhecimento. Assim, o sistema poderá identificar qual informação difere na resposta para o modelo avaliativo construido. Tal processo torna-o mais específico ou genérico segundo a variação da nota atribuida ao documento. O mesmo esperamos que ocorra no último problema listado pelos autores, a confiabilidade do sistema na modelagem do critério de avaliação. Com o ajuste da avaliação pelo professor durante etapas de revisão, esperamos que o sistema modifique seu modelo, refinando-o.

Outra dificuldade citada por \cite{burrows2015} está em encontrar os \textit{datasets} utilizados por trabalhos da literatura, sendo que geralmente as informações coletadas na própria universidade não são disponibilizadas. Neste estudo esperamos realizar comparações em, ao menos, três \textit{datasets} que temos acesso e são conhecidos da literatura e dois \textit{datasets} locais. Nesses \textit{datasets} que temos disponíveis, apresentados em detalhes na Seção \ref{cap5}, encontramos uma variação no padrão de notas (contínuas ou discretas), na avaliação de um ou mais especialistas e na existência ou não de respostas candidatas. Tal variabilidade permite que diferentes testes sejam realizados para investigar o modelo avaliativo do professor, seja ele dado pela nota atribuida ou pela resposta candidata.

É importante descrever ainda a diferença entre o conjunto de informações selecionadas para a classificação correta das respostas e a interpretação avaliativa \cite{ramachandran2015a}. A separação do cunho interpretativo do interlocutor deve ser estritamente analisada conforme o modelo avaliativo. Se os padrões de nota e de resposta estiverem em conformidade com a avaliação do especialista, a redução de dimensionalidade dada pela otimização deve indicar uma boa interpretação da relação termo-classe. Assim, encaramos a avaliação como um processo constante e passível de revisões, para que o ajuste do sistema torne o modelo extraído cada vez mais próximos das expectativas do professor.

\section{Objetivos} \label{cap3-objetivos}

No projeto de pesquisa aqui descrito temos o intuito de ajustar o modelo de correção criado pela máquina aos padrões estabelecidos pelo professor através da sua avaliação por classe (grupo de nota). Segundo a consistência de cada grupo, reduziremos o esforço de correção do professor com a avaliação das respostas que apresentem apenas determinadas caracteristicas textuais. Com padrões bem definidos, esperamos representar o critério avaliativo da questão justificando a classe atribuída através do seu respectivo sumário. Tal sumário, então, são os padrões de cada classe de nota partindo do agrupamento \textit{a priori} das questões. É através desse sumário por nota que recuperamos um possível critério de correção. Desta forma, esperamos que o professor esteja apto para gerenciar o seu método avaliativo em um tempo menor enquanto concentra-se na verificação de aprendizagem do aluno.

Neste projeto, portanto, temos como objetivo aproximar o critério avaliativo do aluno com a definição de padrões de correção e a criação de \textit{feedbacks}. Para isso, serão estudados os padrões avaliativos do professor e os métodos de representação do conhecimento em base de dados de questões discursivas curtas. Para atingir o objetivo geral descrevemos os seguintes objetivos específicos:


\begin{itemize}
\item Estudar o impacto das técnicas de Processamento de Linguagem Natural e Recuperação da Informação para a identificação da relação termo-classe de forma léxica, morfológica, semântica, sintática, estatística ou espacial \cite{burrows2015, butcher2010}.
\item Organizar \textit{datasets} públicos e locais para comparação direta com resultados obtidos em estudos correlatos \cite{burrows2015}.
\item Unificar padrões de respostas dadas por professores e alunos, observando a frequência de ocorrência e co-ocorrência de termos segundo sua relevância \cite{butcher2010}.
\item Criar modelos avaliativos através do reconhecimento de padrões variáveis em categorias em dados discretos e contínuos \cite{burrows2015}.
\item Elaborar e ajustar modelos de acordo com a eficiência do sistema na recuperação da resposta atribuída pelo professor e seu modelo avaliativo \cite{burrows2015}.
\item Identificar a relação da avaliação com o comportamento textual da classe para remoção de \textit{outliers} e manter a consistência da classificação \cite{butcher2010}.
\item Apresentar avaliações adequadas ao formato de correção do professor \cite{butcher2010}.
\item Gerar \textit{feedbacks} que colaborem com o processo avaliativo, como o quadro de \textit{rubrics}, de forma a contribuir com a discussão de resultados e a representação do critério de correção \cite{oliveira2010}.
\end{itemize}